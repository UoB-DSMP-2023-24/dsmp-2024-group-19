{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tapes and lob data\n",
    "\n",
    "do this for each day otherwise memory (RAM) exceeds most computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "from fast_tools import get_data, get_data_gen\n",
    "\n",
    "#data = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "Remove outliers from lob and create an additional columns noting this\n",
    "\n",
    "FFill tapes data to get the most up to date tapes price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\r"
     ]
    }
   ],
   "source": [
    "# code\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "def get_tapes_window(tapes):\n",
    "    dt = 60*60 # in seconds\n",
    "    #stds = []\n",
    "    #means = []\n",
    "    w_bids = []\n",
    "    w_asks = []\n",
    "\n",
    "    t_start = 0\n",
    "    start_time = 0\n",
    "    z = 3.29 # 99.9%\n",
    "\n",
    "    outside = []\n",
    "    while True:\n",
    "        end_time = start_time + dt\n",
    "        t_end = t_start\n",
    "        rolling_tapes = []\n",
    "        while tapes[t_end, 0] < end_time:\n",
    "            rolling_tapes += [tapes[t_end, 1]] * int(tapes[t_end,2])\n",
    "            t_end += 1\n",
    "\n",
    "        mean = np.mean(rolling_tapes)\n",
    "        std = np.std(rolling_tapes)\n",
    "        #means.append(mean)\n",
    "\n",
    "        w_bid = mean - std * z\n",
    "        w_ask = mean + std * z\n",
    "        w_bids.append(w_bid)\n",
    "        w_asks.append(w_ask)\n",
    "\n",
    "        # look one minute a head\n",
    "        local_end = t_end\n",
    "        future_tapes = []\n",
    "        while tapes[local_end, 0] < end_time + 60:\n",
    "            future_tapes += [tapes[local_end, 1]] * int(tapes[local_end,2])\n",
    "            local_end += 1\n",
    "\n",
    "        future_tapes = np.array(future_tapes)\n",
    "\n",
    "        n_above = len(np.where(future_tapes > w_ask)[0])\n",
    "        n_below = len(np.where(future_tapes < w_bid)[0])\n",
    "        if end_time % 60 !=0:\n",
    "            raise ValueError\n",
    "        outside.append((end_time,n_above, n_below, len(future_tapes)))\n",
    "\n",
    "        start_time += 60\n",
    "        while tapes[t_start, 0] < start_time:\n",
    "            t_start += 1\n",
    "\n",
    "        end_time += dt\n",
    "        if end_time >= 8.5*60*60:\n",
    "            break\n",
    "\n",
    "    return outside, w_bids, w_asks\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_features(lob_data: np.array, \n",
    "                 lob_times: np.array, \n",
    "                 tapes: np.array, \n",
    "                 time_step_s: int, \n",
    "                 window_data: np.array,\n",
    "                 ab_weight = 1, \n",
    "                 median = True, \n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Calculate features from LOB and Tapes data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lob_data : np.array\n",
    "        Array containing the limit order book (LOB) data.\n",
    "    lob_times : np.array\n",
    "        Array containing timestamps for the LOB data.\n",
    "    tapes : np.array\n",
    "        Array containing Tapes data.\n",
    "    time_step_s : int\n",
    "        Time step in seconds for calculating features.\n",
    "    ab_weight : float, optional\n",
    "        Weight parameter for alpha and beta calculations, by default 1.\n",
    "    median : bool, optional\n",
    "        Whether to calculate features using median instead of mean, by default False.\n",
    "    window_data : np.array\n",
    "        Array containing window data for calculating CBS and CAS, by default None.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        A tuple containing:\n",
    "        - feat_arr: np.array\n",
    "            Array containing feature values.\n",
    "        - features: list\n",
    "            List of feature names.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_rows = int((8.5 * 60 * 60) / time_step_s)                         # define number of rows of output array\n",
    "    features = [\"MP\",\"HIBID\",\"LOASK\",\"AP\",\"WBP\",\"WAP\",                  # define features\n",
    "                \"TCBS\",\"TCAS\",\"AWS\",\"VOL\",\"GAP\",\"SPREAD\",\n",
    "                \"ALPHA\", \"BETA\", \"ZETA\", \"ENDT\", \n",
    "                \"PSTD\", \"LOWIN\", \"HIWIN\", \"nUoD\"]\n",
    "    n_features = len(features)                                          # define number of features\n",
    "\n",
    "    feat_arr = np.zeros((n_rows, n_features), dtype=np.float64)         # array to hold feature values\n",
    "    \n",
    "    LA_HB_a_b = np.zeros((lob_data.shape[0]+1, 4), dtype = np.float64)  # array holding the LOASK, HIBID,\n",
    "                                                                        # alpha, beta, values \n",
    "\n",
    "    for i in prange(lob_data.shape[0]):                                 # iterates over the LOB to fill\n",
    "        row = lob_data[i]                                               # LA_HB_a_b values\n",
    "        \n",
    "        neg_ind = np.where(row < 0)[0]                                  # locate bid and ask prices (indicies)\n",
    "        pos_ind = np.where(row > 0)[0]\n",
    "        \n",
    "        if len(neg_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][1] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][1] = max(neg_ind) + 1 \n",
    "\n",
    "        if len(pos_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][0] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][0] = min(pos_ind) + 1\n",
    "\n",
    "        mid_price = (LA_HB_a_b[i][0] + LA_HB_a_b[i][1]) / 2             # calculate mid_price for alpha/beta calculations\n",
    "\n",
    "        if np.isnan(mid_price):\n",
    "            alpha = np.nan\n",
    "            beta = np.nan\n",
    "        else:                                                           # calculate alpha/beta using ab_weight var\n",
    "            beta = 0\n",
    "            for ind in neg_ind:\n",
    "                beta += (-1 * row[ind]) / ((mid_price - (ind + 1)) + ab_weight)\n",
    "    \n",
    "            alpha = 0\n",
    "            for ind in pos_ind:\n",
    "                alpha += row[ind] / (((ind + 1) - mid_price) + ab_weight)\n",
    "                \n",
    "\n",
    "        LA_HB_a_b[i][2] = alpha\n",
    "        LA_HB_a_b[i][3] = beta\n",
    "        \n",
    "    max_lob = lob_data.shape[0] - 1                                      # define max indicies for lob\n",
    "    max_tapes = tapes.shape[0] - 1                                       # define max indicies for tapes\n",
    "    \n",
    "    start_time = 0                                                       # define start time\n",
    "    lob_start = 0                                                        # define start index for lob\n",
    "    tapes_start = 0                                                      # define start index for tapes\n",
    "    \n",
    "    cas = np.zeros(800, dtype = np.int16)                                # define an array to hold CAS values\n",
    "    cbs = np.zeros(800, dtype = np.int16)                                # define an array to hold CBS values\n",
    "    for row_i in range(n_rows):\n",
    "        end_time = start_time + time_step_s                              # move to next time step\n",
    "        lob_end = lob_start\n",
    "        tapes_end = tapes_start\n",
    "\n",
    "        # get lob end index\n",
    "        while lob_times[lob_end] < end_time and lob_end < max_lob:       # move lob indicies to end time\n",
    "            lob_end += 1\n",
    "        \n",
    "        # get tapes end index\n",
    "        while tapes[tapes_end][0] < end_time and tapes_end < max_tapes:  # move tapes indicies to end time\n",
    "            tapes_end += 1\n",
    "\n",
    "        # feature calculations\n",
    "        if tapes_start == tapes_end:                                     # if there is no tapes data\n",
    "            AP = np.nan                                                  # set tapes features to np.nan\n",
    "            VOL = np.nan\n",
    "            PSTD = np.nan\n",
    "            nUoD = np.nan\n",
    "        else:\n",
    "            tapes_slice = tapes[tapes_start:tapes_end]                   # extract tapes slice, calculate AP, VOL\n",
    "            tapes_list = []\n",
    "            \n",
    "            for row in tapes_slice:\n",
    "                for _ in range(int(row[2])):\n",
    "                    tapes_list.append(row[1])\n",
    "\n",
    "            tapes_list = np.array(tapes_list, dtype=np.int32)\n",
    "            AP = np.mean(tapes_list)\n",
    "            VOL = np.sum(tapes_slice[:,2])\n",
    "            PSTD = np.std(tapes_list)\n",
    "\n",
    "            tapes_price_diff = tapes_slice[:,1][1:] - tapes_slice[:,1][:-1]\n",
    "            n_ups = np.sum(tapes_price_diff > 0)\n",
    "            n_downs = np.sum(tapes_price_diff < 0)\n",
    "            nUoD = (n_ups + 1) / (n_downs + 1) - 1\n",
    "\n",
    "        if lob_start == lob_end:                                         # if there is no LOB data\n",
    "            MP = np.nan                                                  # set lob features to np.nan\n",
    "            HIBID = np.nan\n",
    "            LOASK = np.nan\n",
    "            SPREAD = np.nan\n",
    "            TCBS = np.nan\n",
    "            TCAS = np.nan\n",
    "            WBP = np.nan\n",
    "            WAP = np.nan\n",
    "            AWS = np.nan\n",
    "            ALPHA = np.nan\n",
    "            BETA = np.nan\n",
    "            ZETA = np.nan  \n",
    "        else:\n",
    "            lob_slice = lob_data[lob_start:lob_end]                       # extract slices of data \n",
    "            LA_HB_a_b_slice = LA_HB_a_b[lob_start:lob_end]                \n",
    "\n",
    "            # midprice_calcs, alpha, beta\n",
    "            if median:                                                    # calculate price features\n",
    "                HIBID = np.median(LA_HB_a_b_slice[:,1])                   # using median if set to true\n",
    "                LOASK = np.median(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.median(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.median(LA_HB_a_b_slice[:,3])\n",
    "            else:\n",
    "                HIBID = np.nanmean(LA_HB_a_b_slice[:,1])\n",
    "                LOASK = np.nanmean(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.nanmean(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.nanmean(LA_HB_a_b_slice[:,3])\n",
    "\n",
    "            MP = (HIBID + LOASK) / 2\n",
    "            SPREAD = LOASK - HIBID\n",
    "            ZETA = BETA - ALPHA\n",
    "\n",
    "            if HIBID >= LOASK:\n",
    "                print(\"WARNING: HIBID >= LOASK\")\n",
    "\n",
    "            # consolidated calcs\n",
    "            cas[:] = 0                                                      # reset cas, cbs arrays for new data\n",
    "            cbs[:] = 0 \n",
    "\n",
    "            window_index = np.where(window_data[:,0] == end_time)[0]\n",
    "            if len(window_index) == 1:\n",
    "                w_bid = window_data[window_index[0], 4]\n",
    "                w_ask = window_data[window_index[0], 5]\n",
    "                LOWIN = window_data[window_index[0], 1]\n",
    "                HIWIN = window_data[window_index[0], 2]\n",
    "            else:\n",
    "                w_bid = MP - 100\n",
    "                w_ask = MP + 100\n",
    "                LOWIN = 0\n",
    "                HIWIN = 0\n",
    "\n",
    "            for ci in prange(int(np.floor(w_bid) - 1), int(np.ceil(w_ask) + 2)):\n",
    "                # can optimise with LOASK AND HIBID here\n",
    "                                                                        # only calculate cbs between window left of MP\n",
    "                cbs_vec = lob_slice[:,ci].copy() * -1                   # and less than LOASK + 100 for efficiency\n",
    "                cbs_vec[cbs_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cbs[ci] = np.sum(np.abs(np.diff(cbs_vec))) + cbs_vec[0]\n",
    "\n",
    "                                                                        # only calculate cas between window right of MP\n",
    "                cas_vec = lob_slice[:,ci].copy()                        # and greater than HIBID - 100 for efficiency\n",
    "                cas_vec[cas_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cas[ci] = np.sum(np.abs(np.diff(cas_vec))) + cas_vec[0]\n",
    "\n",
    "            TCBS = np.sum(cbs)                                              # Total CBS\n",
    "            TCAS = np.sum(cas)                                              # Total CAS\n",
    "\n",
    "            if TCBS == 0:                                                   # Calculate WBP, np.nan if no activity\n",
    "                WBP = np.nan\n",
    "            else:\n",
    "                WBP = 0\n",
    "                for ci in prange(800):\n",
    "                    WBP += (ci + 1) * (cbs[ci] / TCBS)\n",
    "\n",
    "            if TCAS == 0:                                                   # Calculate WAP, np.nan if no activity\n",
    "                WAP = np.nan\n",
    "            else:\n",
    "                WAP = 0\n",
    "                for ci in prange(800):\n",
    "                    WAP += (ci + 1) * (cas[ci] / TCAS)\n",
    "\n",
    "            AWS = WAP - WBP                                                 # Activity weighted spread calc\n",
    "\n",
    "        # feature setting\n",
    "        feat_arr[row_i][features.index(\"AP\")] = AP                          # set the values to the feat_arr\n",
    "        feat_arr[row_i][features.index(\"VOL\")] = VOL\n",
    "        feat_arr[row_i][features.index(\"MP\")] = MP\n",
    "        feat_arr[row_i][features.index(\"HIBID\")] = HIBID\n",
    "        feat_arr[row_i][features.index(\"LOASK\")] = LOASK\n",
    "        feat_arr[row_i][features.index(\"SPREAD\")] = SPREAD / MP\n",
    "        feat_arr[row_i][features.index(\"TCAS\")] = TCAS\n",
    "        feat_arr[row_i][features.index(\"TCBS\")] = TCBS\n",
    "        feat_arr[row_i][features.index(\"WAP\")] = WAP\n",
    "        feat_arr[row_i][features.index(\"WBP\")] = WBP\n",
    "        feat_arr[row_i][features.index(\"AWS\")] = AWS / MP\n",
    "        feat_arr[row_i][features.index(\"ALPHA\")] = ALPHA\n",
    "        feat_arr[row_i][features.index(\"BETA\")] = BETA\n",
    "        feat_arr[row_i][features.index(\"ZETA\")] = ZETA\n",
    "        feat_arr[row_i][features.index(\"GAP\")] = 1 - (MP / AP)\n",
    "        feat_arr[row_i][features.index(\"ENDT\")] = end_time\n",
    "        feat_arr[row_i][features.index(\"PSTD\")] = PSTD / MP\n",
    "        feat_arr[row_i][features.index(\"LOWIN\")] = LOWIN\n",
    "        feat_arr[row_i][features.index(\"HIWIN\")] = HIWIN\n",
    "        feat_arr[row_i][features.index(\"nUoD\")] = nUoD\n",
    "\n",
    "\n",
    "        # adjust start times\n",
    "        start_time = end_time                                                # Set the next start times and \n",
    "        lob_start = lob_end                                                  # indicies to the last end times / indicies\n",
    "        tapes_start = tapes_end\n",
    "\n",
    "    return feat_arr, features\n",
    "\n",
    "window_length_s = 1 * 60\n",
    "c = 0\n",
    "all_features = []\n",
    "for lob, lob_times, tapes in get_data_gen():\n",
    "    print(c, end = \"\\r\")\n",
    "    outside, w_bids, w_asks = get_tapes_window(tapes)\n",
    "    window_data = np.zeros((len(outside), 6), dtype = float)\n",
    "    for i in range(len(outside)):\n",
    "        window_data[i][:4] = outside[i]\n",
    "        window_data[i][4] = w_bids[i]\n",
    "        window_data[i][5] = w_asks[i]\n",
    "\n",
    "    features = get_features(lob, lob_times, tapes, window_length_s, window_data)\n",
    "    all_features.append(features)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>HIBID</th>\n",
       "      <th>LOASK</th>\n",
       "      <th>AP</th>\n",
       "      <th>WBP</th>\n",
       "      <th>WAP</th>\n",
       "      <th>TCBS</th>\n",
       "      <th>TCAS</th>\n",
       "      <th>AWS</th>\n",
       "      <th>VOL</th>\n",
       "      <th>...</th>\n",
       "      <th>ZETA</th>\n",
       "      <th>ENDT</th>\n",
       "      <th>PSTD</th>\n",
       "      <th>LOWIN</th>\n",
       "      <th>HIWIN</th>\n",
       "      <th>nUoD</th>\n",
       "      <th>WMP</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "      <th>MP_perc(y)</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>509.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>510.0</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>120.809430</td>\n",
       "      <td>108.336935</td>\n",
       "      <td>133.283333</td>\n",
       "      <td>107.773434</td>\n",
       "      <td>97.821416</td>\n",
       "      <td>119.812024</td>\n",
       "      <td>799.272549</td>\n",
       "      <td>389.211765</td>\n",
       "      <td>0.183207</td>\n",
       "      <td>108.692157</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134480</td>\n",
       "      <td>15330.000000</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576471</td>\n",
       "      <td>-0.300610</td>\n",
       "      <td>108.816720</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>-0.003664</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.717613</td>\n",
       "      <td>1.516618</td>\n",
       "      <td>14.955586</td>\n",
       "      <td>1.438187</td>\n",
       "      <td>14.256804</td>\n",
       "      <td>13.093612</td>\n",
       "      <td>556.606094</td>\n",
       "      <td>238.180699</td>\n",
       "      <td>0.221884</td>\n",
       "      <td>12.428077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679299</td>\n",
       "      <td>8842.115132</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.374537</td>\n",
       "      <td>0.156839</td>\n",
       "      <td>3.229437</td>\n",
       "      <td>10.870564</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>101.575472</td>\n",
       "      <td>59.121086</td>\n",
       "      <td>105.265306</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815077</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>93.861267</td>\n",
       "      <td>-52.500000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>107.077170</td>\n",
       "      <td>103.541460</td>\n",
       "      <td>112.702025</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>233.250000</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643348</td>\n",
       "      <td>7695.000000</td>\n",
       "      <td>0.016214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.408670</td>\n",
       "      <td>108.102343</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>108.102273</td>\n",
       "      <td>105.201785</td>\n",
       "      <td>113.984241</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034204</td>\n",
       "      <td>15330.000000</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.316986</td>\n",
       "      <td>109.413179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>108.754597</td>\n",
       "      <td>106.018000</td>\n",
       "      <td>115.434346</td>\n",
       "      <td>729.500000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>0.085921</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514588</td>\n",
       "      <td>22965.000000</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>110.180411</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>110.213483</td>\n",
       "      <td>107.823881</td>\n",
       "      <td>177.776699</td>\n",
       "      <td>2743.000000</td>\n",
       "      <td>1185.000000</td>\n",
       "      <td>0.777341</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.367177</td>\n",
       "      <td>30600.000000</td>\n",
       "      <td>0.060611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>136.648350</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.291022</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MP       HIBID       LOASK          AP         WBP         WAP  \\\n",
       "count  509.000000  509.000000  510.000000  510.000000  510.000000  510.000000   \n",
       "mean   120.809430  108.336935  133.283333  107.773434   97.821416  119.812024   \n",
       "std      7.717613    1.516618   14.955586    1.438187   14.256804   13.093612   \n",
       "min    101.500000   94.000000  107.000000  101.575472   59.121086  105.265306   \n",
       "25%    115.750000  108.000000  123.000000  107.077170  103.541460  112.702025   \n",
       "50%    119.000000  108.000000  130.000000  108.102273  105.201785  113.984241   \n",
       "75%    124.000000  109.000000  140.000000  108.754597  106.018000  115.434346   \n",
       "max    168.000000  112.000000  227.000000  110.213483  107.823881  177.776699   \n",
       "\n",
       "              TCBS         TCAS         AWS         VOL  ...        ZETA  \\\n",
       "count   510.000000   510.000000  509.000000  510.000000  ...  510.000000   \n",
       "mean    799.272549   389.211765    0.183207  108.692157  ...    1.134480   \n",
       "std     556.606094   238.180699    0.221884   12.428077  ...    0.679299   \n",
       "min     145.000000    98.000000   -0.000338   69.000000  ...   -0.815077   \n",
       "25%     472.000000   233.250000    0.057478  101.000000  ...    0.643348   \n",
       "50%     556.000000   298.000000    0.068661  109.000000  ...    1.034204   \n",
       "75%     729.500000   443.000000    0.085921  117.000000  ...    1.514588   \n",
       "max    2743.000000  1185.000000    0.777341  140.000000  ...    4.367177   \n",
       "\n",
       "               ENDT        PSTD  LOWIN       HIWIN        nUoD         WMP  \\\n",
       "count    510.000000  509.000000  510.0  510.000000  510.000000  510.000000   \n",
       "mean   15330.000000    0.023464    0.0    1.576471   -0.300610  108.816720   \n",
       "std     8842.115132    0.009975    0.0    4.374537    0.156839    3.229437   \n",
       "min       60.000000    0.009332    0.0    0.000000   -0.687500   93.861267   \n",
       "25%     7695.000000    0.016214    0.0    0.000000   -0.408670  108.102343   \n",
       "50%    15330.000000    0.019388    0.0    0.000000   -0.316986  109.413179   \n",
       "75%    22965.000000    0.029293    0.0    0.000000   -0.200000  110.180411   \n",
       "max    30600.000000    0.060611    0.0   38.000000    0.166667  136.648350   \n",
       "\n",
       "       MP_diff(y)  MP_perc(y)    DAY  \n",
       "count  507.000000  507.000000  510.0  \n",
       "mean     0.007890   -0.003664  124.0  \n",
       "std     10.870564    0.087142    0.0  \n",
       "min    -52.500000   -0.454545  124.0  \n",
       "25%     -6.000000   -0.050000  124.0  \n",
       "50%      0.000000    0.000000  124.0  \n",
       "75%      5.125000    0.042598  124.0  \n",
       "max     47.000000    0.291022  124.0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [pd.DataFrame(fa, columns=f) for fa, f in all_features]\n",
    "for i, df in enumerate(dfs):\n",
    "    df[\"WMP\"] = (df[\"WBP\"] + df[\"WAP\"]) / 2\n",
    "    df[\"MP_diff(y)\"] = df[\"MP\"].diff(1)\n",
    "    \n",
    "    df[\"MP_perc(y)\"] = df[\"MP_diff(y)\"] / df[\"MP\"]\n",
    "    df[\"DAY\"] = i\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from LOB and Tapes\n",
    "\n",
    "get mean, std, trend, delta from 60 min segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCAS_std</th>\n",
       "      <th>TCAS_mean</th>\n",
       "      <th>TCAS_close</th>\n",
       "      <th>TCAS_delta</th>\n",
       "      <th>TCAS_corr</th>\n",
       "      <th>TCBS_std</th>\n",
       "      <th>TCBS_mean</th>\n",
       "      <th>TCBS_close</th>\n",
       "      <th>TCBS_delta</th>\n",
       "      <th>TCBS_corr</th>\n",
       "      <th>...</th>\n",
       "      <th>PSTD_mean</th>\n",
       "      <th>PSTD_close</th>\n",
       "      <th>PSTD_delta</th>\n",
       "      <th>PSTD_corr</th>\n",
       "      <th>LOWIN_sum</th>\n",
       "      <th>HIWIN_sum</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "      <th>MP_perc(y)</th>\n",
       "      <th>DAY</th>\n",
       "      <th>ENDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>173.435675</td>\n",
       "      <td>764.000000</td>\n",
       "      <td>404.0</td>\n",
       "      <td>-792.0</td>\n",
       "      <td>-0.275200</td>\n",
       "      <td>428.585872</td>\n",
       "      <td>1370.983333</td>\n",
       "      <td>471.0</td>\n",
       "      <td>-820.0</td>\n",
       "      <td>-0.281637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0</td>\n",
       "      <td>3660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>176.232924</td>\n",
       "      <td>748.300000</td>\n",
       "      <td>254.0</td>\n",
       "      <td>-590.0</td>\n",
       "      <td>-0.281038</td>\n",
       "      <td>438.983360</td>\n",
       "      <td>1359.900000</td>\n",
       "      <td>626.0</td>\n",
       "      <td>-1271.0</td>\n",
       "      <td>-0.328495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.084350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.50</td>\n",
       "      <td>-0.087719</td>\n",
       "      <td>0</td>\n",
       "      <td>3720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>178.931520</td>\n",
       "      <td>742.333333</td>\n",
       "      <td>486.0</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-0.302718</td>\n",
       "      <td>438.246068</td>\n",
       "      <td>1342.316667</td>\n",
       "      <td>842.0</td>\n",
       "      <td>-926.0</td>\n",
       "      <td>-0.326624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.019056</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>179.974673</td>\n",
       "      <td>740.316667</td>\n",
       "      <td>588.0</td>\n",
       "      <td>-398.0</td>\n",
       "      <td>-0.330746</td>\n",
       "      <td>435.905336</td>\n",
       "      <td>1330.933333</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>-258.0</td>\n",
       "      <td>-0.316472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.018532</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0.140356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0</td>\n",
       "      <td>3840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>178.095208</td>\n",
       "      <td>733.716667</td>\n",
       "      <td>590.0</td>\n",
       "      <td>-466.0</td>\n",
       "      <td>-0.317706</td>\n",
       "      <td>436.393934</td>\n",
       "      <td>1328.033333</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>-0.325841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>0</td>\n",
       "      <td>3900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>179.894290</td>\n",
       "      <td>836.666667</td>\n",
       "      <td>842.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>-0.069611</td>\n",
       "      <td>330.086495</td>\n",
       "      <td>1404.850000</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>0.128992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-0.015464</td>\n",
       "      <td>0</td>\n",
       "      <td>30360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>179.192103</td>\n",
       "      <td>841.416667</td>\n",
       "      <td>955.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>-0.078436</td>\n",
       "      <td>326.716355</td>\n",
       "      <td>1410.300000</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.251713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.164992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0</td>\n",
       "      <td>30420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>179.739357</td>\n",
       "      <td>840.883333</td>\n",
       "      <td>641.0</td>\n",
       "      <td>-432.0</td>\n",
       "      <td>-0.137357</td>\n",
       "      <td>320.014817</td>\n",
       "      <td>1420.816667</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.219803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>-0.010282</td>\n",
       "      <td>0.044937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-0.024138</td>\n",
       "      <td>0</td>\n",
       "      <td>30480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>177.331300</td>\n",
       "      <td>837.900000</td>\n",
       "      <td>894.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>-0.092298</td>\n",
       "      <td>302.631865</td>\n",
       "      <td>1431.233333</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0.098372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0</td>\n",
       "      <td>30540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>171.121630</td>\n",
       "      <td>849.566667</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>-0.126939</td>\n",
       "      <td>293.416035</td>\n",
       "      <td>1436.383333</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.032535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>0.093043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-0.010363</td>\n",
       "      <td>0</td>\n",
       "      <td>30600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TCAS_std   TCAS_mean  TCAS_close  TCAS_delta  TCAS_corr    TCBS_std  \\\n",
       "60   173.435675  764.000000       404.0      -792.0  -0.275200  428.585872   \n",
       "61   176.232924  748.300000       254.0      -590.0  -0.281038  438.983360   \n",
       "62   178.931520  742.333333       486.0      -223.0  -0.302718  438.246068   \n",
       "63   179.974673  740.316667       588.0      -398.0  -0.330746  435.905336   \n",
       "64   178.095208  733.716667       590.0      -466.0  -0.317706  436.393934   \n",
       "..          ...         ...         ...         ...        ...         ...   \n",
       "505  179.894290  836.666667       842.0       172.0  -0.069611  330.086495   \n",
       "506  179.192103  841.416667       955.0       282.0  -0.078436  326.716355   \n",
       "507  179.739357  840.883333       641.0      -432.0  -0.137357  320.014817   \n",
       "508  177.331300  837.900000       894.0       493.0  -0.092298  302.631865   \n",
       "509  171.121630  849.566667      1101.0       684.0  -0.126939  293.416035   \n",
       "\n",
       "       TCBS_mean  TCBS_close  TCBS_delta  TCBS_corr  ...  PSTD_mean  \\\n",
       "60   1370.983333       471.0      -820.0  -0.281637  ...   0.014475   \n",
       "61   1359.900000       626.0     -1271.0  -0.328495  ...   0.014467   \n",
       "62   1342.316667       842.0      -926.0  -0.326624  ...   0.014531   \n",
       "63   1330.933333      1085.0      -258.0  -0.316472  ...   0.014651   \n",
       "64   1328.033333      1169.0      -273.0  -0.325841  ...   0.014666   \n",
       "..           ...         ...         ...        ...  ...        ...   \n",
       "505  1404.850000      1950.0       909.0   0.284667  ...   0.013974   \n",
       "506  1410.300000      1368.0       474.0   0.251713  ...   0.014045   \n",
       "507  1420.816667      1525.0       931.0   0.219803  ...   0.014011   \n",
       "508  1431.233333      1219.0       473.0   0.133301  ...   0.013975   \n",
       "509  1436.383333      1055.0       463.0   0.032535  ...   0.013911   \n",
       "\n",
       "     PSTD_close  PSTD_delta  PSTD_corr  LOWIN_sum  HIWIN_sum  MP_diff(y)  \\\n",
       "60     0.015244   -0.000243   0.068848        0.0        0.0       16.25   \n",
       "61     0.015007   -0.000262   0.084350        0.0        0.0      -22.50   \n",
       "62     0.019056    0.007771   0.134761        0.0        0.0        0.00   \n",
       "63     0.018532    0.006809   0.140356        0.0        0.0        9.00   \n",
       "64     0.012614    0.000186   0.092290        0.0        0.0       -2.50   \n",
       "..          ...         ...        ...        ...        ...         ...   \n",
       "505    0.012572   -0.001114   0.128992        0.0        1.0       -4.50   \n",
       "506    0.017966    0.008540   0.164992        0.0        1.0        6.00   \n",
       "507    0.007334   -0.010282   0.044937        0.0        0.0       -7.00   \n",
       "508    0.015466   -0.000135   0.098372        0.0        0.0        2.50   \n",
       "509    0.011790   -0.003560   0.093043        0.0        0.0       -3.00   \n",
       "\n",
       "     MP_perc(y)  DAY     ENDT  \n",
       "60     0.058244    0   3660.0  \n",
       "61    -0.087719    0   3720.0  \n",
       "62     0.000000    0   3780.0  \n",
       "63     0.033898    0   3840.0  \n",
       "64    -0.009506    0   3900.0  \n",
       "..          ...  ...      ...  \n",
       "505   -0.015464    0  30360.0  \n",
       "506    0.020202    0  30420.0  \n",
       "507   -0.024138    0  30480.0  \n",
       "508    0.008547    0  30540.0  \n",
       "509   -0.010363    0  30600.0  \n",
       "\n",
       "[450 rows x 59 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "features = [\"TCAS\", \"TCBS\", \"ALPHA\", \"BETA\", \"ZETA\",\n",
    "            \"WMP\", \"AWS\", \"VOL\", \"GAP\", \"nUoD\", \"PSTD\"]\n",
    "\n",
    "sum_features = [\"LOWIN\", \"HIWIN\"]\n",
    "\n",
    "y_feats = [\"MP_diff(y)\", \"MP_perc(y)\", \"DAY\"]\n",
    "\n",
    "X_dfs = []\n",
    "\n",
    "\n",
    "\n",
    "for c, df in enumerate(dfs):\n",
    "    print(c, end = \"\\r\")\n",
    "\n",
    "    X_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df) - 60):\n",
    "        train_segment = df[i:i+60]\n",
    "        test_segment = df[i+60:i+61]\n",
    "\n",
    "        row = {}\n",
    "        for f in features:\n",
    "            # std\n",
    "            row[f+\"_std\"] = np.std(train_segment[f])\n",
    "            # mean\n",
    "            if f != \"WMP\": # exclude mean midprice\n",
    "                row[f+\"_mean\"] = np.mean(train_segment[f])\n",
    "                row[f+\"_close\"] = train_segment[f].iloc[-1]\n",
    "            # delta\n",
    "            row[f+\"_delta\"] = train_segment[f].iloc[-1] - train_segment[f].iloc[0]\n",
    "            # trend\n",
    "            row[f+\"_corr\"] = np.corrcoef(np.arange(len(train_segment[f])), train_segment[f].to_numpy())[0, 1]\n",
    "\n",
    "        for f in sum_features:\n",
    "            row[f+\"_sum\"] = np.sum(train_segment[f])\n",
    "\n",
    "        for yf in y_feats:\n",
    "            row[yf] = test_segment[yf].iloc[0]\n",
    "        row[\"ENDT\"] = test_segment[\"ENDT\"]\n",
    "\n",
    "        X_df = pd.concat([X_df, pd.DataFrame(row)])\n",
    "\n",
    "    X_dfs.append(X_df)\n",
    "\n",
    "X_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = pd.concat(X_dfs[:], axis = 0)\n",
    "merged_dfs.to_csv(f\"final_merged_{window_length_s}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clean_merge_dfs = merged_dfs.dropna(how=\"any\")\n",
    "\n",
    "x_features = list(X_df)\n",
    "x_features.remove(y_feat)\n",
    "\n",
    "X = clean_merge_dfs[x_features]\n",
    "y = 1 / (1 + np.exp(-clean_merge_dfs[y_feat]/4))\n",
    "\n",
    "baseline_mae = np.mean(np.abs(y - 0.5))\n",
    "print(\"Baseline MAE: \", baseline_mae)\n",
    "print(\"Samples: \", len(merged_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X contains your input features and y contains your target values\n",
    "# X shape: (number of samples, 35)\n",
    "\n",
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "# Step 2: Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DTR = DecisionTreeRegressor(max_leaf_nodes=10)\n",
    "DTR.fit(X_train, y_train)\n",
    "\n",
    "ypred = DTR.predict(X_test)\n",
    "print(mean_absolute_error(ypred, y_test))\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plot_tree(DTR, feature_names=x_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(ypred)\n",
    "plt.plot(y_test.to_numpy())\n",
    "plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(x_features, DTR.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svc = SVR()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "ypred = SVR.predict(X_test)\n",
    "print(mean_absolute_error(ypred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "\n",
    "def create_regression_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "        layers.Dropout(0.2),  # Add Dropout layer\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid')  # Output layer with single neuron for regression\n",
    "    ])\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=0.05)\n",
    "    model.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (len(x_features),)\n",
    "regression_model = create_regression_model(input_shape)\n",
    "\n",
    "# Display model architecture\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "history = regression_model.fit(X_train_normalized, y_train, epochs=1000, batch_size=512, validation_split=0.5, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.axhline(baseline_mae, c = \"black\", linestyle = \"--\")\n",
    "plt.show()\n",
    "\n",
    "test_loss = regression_model.evaluate(X_test_normalized, y_test)\n",
    "model_filename = f\"regression_model_test_score_{test_loss[-1]:.4f}.keras\"\n",
    "regression_model.save(model_filename)\n",
    "# Print the test loss\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features\n",
    "\n",
    "for use in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs.to_csv(\"final_merged_5s.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged_dfs = pd.read_csv(\"final_merged_15s.csv\", index_col=0)\n",
    "plt.figure(figsize=(50,40))\n",
    "sns.heatmap(merged_dfs.corr(), vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "merged_dfs = pd.read_csv(\"final_merged_15s.csv\", index_col=0)\n",
    "x_features = list(merged_dfs)\n",
    "x_features.remove(\"MP_diff(y)\")\n",
    "x_features.remove(\"LOWIN_sum\")\n",
    "\n",
    "clean_dfs = merged_dfs.dropna(how=\"any\")\n",
    "\n",
    "for col in x_features:\n",
    "    std = clean_dfs[col].std()\n",
    "    mean = clean_dfs[col].mean()\n",
    "\n",
    "    clean_dfs[col] = (clean_dfs[col] - mean) / std\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_results = pca.fit_transform(clean_dfs[x_features])\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(pca_results[:,0], pca_results[:,1], c = np.log(clean_dfs[\"MP_diff(y)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
