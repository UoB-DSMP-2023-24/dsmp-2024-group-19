{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tapes and lob data\n",
    "\n",
    "do this for each day otherwise memory (RAM) exceeds most computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to reach each day: 0.17849993705749512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [-6,  0,  0, ...,  0,  0,  0],\n",
       "        [-6,  0,  0, ...,  0,  0,  1],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8),\n",
       " array([0.0000000e+00, 2.7900000e-01, 1.3330000e+00, ..., 3.0599635e+04,\n",
       "        3.0599759e+04, 3.0599945e+04]),\n",
       " array([[1.1067000e+01, 2.6900000e+02, 1.0000000e+00],\n",
       "        [1.1222000e+01, 2.6700000e+02, 2.0000000e+00],\n",
       "        [1.2338000e+01, 2.7000000e+02, 2.0000000e+00],\n",
       "        ...,\n",
       "        [3.0599108e+04, 2.9200000e+02, 1.0000000e+00],\n",
       "        [3.0599728e+04, 2.9000000e+02, 1.0000000e+00],\n",
       "        [3.0599728e+04, 2.8800000e+02, 1.0000000e+00]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "from fast_tools import get_data\n",
    "\n",
    "data = get_data(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "Remove outliers from lob and create an additional columns noting this\n",
    "\n",
    "FFill tapes data to get the most up to date tapes price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "def get_tapes_window(tapes):\n",
    "    dt = 60*60 # in seconds\n",
    "    #stds = []\n",
    "    #means = []\n",
    "    w_bids = []\n",
    "    w_asks = []\n",
    "\n",
    "    t_start = 0\n",
    "    start_time = 0\n",
    "    z = 3.29 # 99.9%\n",
    "\n",
    "    outside = []\n",
    "    while True:\n",
    "        end_time = start_time + dt\n",
    "        t_end = t_start\n",
    "        rolling_tapes = []\n",
    "        while tapes[t_end, 0] < end_time:\n",
    "            rolling_tapes += [tapes[t_end, 1]] * int(tapes[t_end,2])\n",
    "            t_end += 1\n",
    "\n",
    "        mean = np.mean(rolling_tapes)\n",
    "        std = np.std(rolling_tapes)\n",
    "        #means.append(mean)\n",
    "\n",
    "        w_bid = mean - std * z\n",
    "        w_ask = mean + std * z\n",
    "        w_bids.append(w_bid)\n",
    "        w_asks.append(w_ask)\n",
    "\n",
    "        # look one minute a head\n",
    "        local_end = t_end\n",
    "        future_tapes = []\n",
    "        while tapes[local_end, 0] < end_time + 60:\n",
    "            future_tapes += [tapes[local_end, 1]] * int(tapes[local_end,2])\n",
    "            local_end += 1\n",
    "\n",
    "        future_tapes = np.array(future_tapes)\n",
    "\n",
    "        n_above = len(np.where(future_tapes > w_ask)[0])\n",
    "        n_below = len(np.where(future_tapes < w_bid)[0])\n",
    "        if end_time % 60 !=0:\n",
    "            raise ValueError\n",
    "        outside.append((end_time,n_above, n_below, len(future_tapes)))\n",
    "\n",
    "        start_time += 60\n",
    "        while tapes[t_start, 0] < start_time:\n",
    "            t_start += 1\n",
    "\n",
    "        end_time += dt\n",
    "        if end_time >= 8.5*60*60:\n",
    "            break\n",
    "\n",
    "    return outside, w_bids, w_asks\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_features(lob_data: np.array, \n",
    "                 lob_times: np.array, \n",
    "                 tapes: np.array, \n",
    "                 time_step_s: int, \n",
    "                 window_data: np.array,\n",
    "                 ab_weight = 1, \n",
    "                 median = False, \n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Calculate features from LOB and Tapes data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lob_data : np.array\n",
    "        Array containing the limit order book (LOB) data.\n",
    "    lob_times : np.array\n",
    "        Array containing timestamps for the LOB data.\n",
    "    tapes : np.array\n",
    "        Array containing Tapes data.\n",
    "    time_step_s : int\n",
    "        Time step in seconds for calculating features.\n",
    "    ab_weight : float, optional\n",
    "        Weight parameter for alpha and beta calculations, by default 1.\n",
    "    median : bool, optional\n",
    "        Whether to calculate features using median instead of mean, by default False.\n",
    "    cas_cbs_window : int, optional\n",
    "        Size of the window for calculating CAS and CBS, by default 800.\n",
    "    daily_data : bool, optional\n",
    "        Whether to calculate daily features, by default False.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        A tuple containing:\n",
    "        - feat_arr: np.array\n",
    "            Array containing feature values.\n",
    "        - features: list\n",
    "            List of feature names.\n",
    "        - daily_arr: dict or None\n",
    "            Dictionary containing daily features or None if daily_data=False.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_rows = int((8.5 * 60 * 60) / time_step_s)                         # define number of rows of output array\n",
    "    features = [\"MP\",\"HIBID\",\"LOASK\",\"AP\",\"WBP\",\"WAP\",                  # define features\n",
    "                \"TCBS\",\"TCAS\",\"AWS\",\"VOL\",\"GAP\",\"SPREAD\",\n",
    "                \"ALPHA\", \"BETA\", \"ZETA\", \"ENDT\", \n",
    "                \"PSTD\", \"LOWIN\", \"HIWIN\", \"nUoD\"]\n",
    "    n_features = len(features)                                          # define number of features\n",
    "\n",
    "    feat_arr = np.zeros((n_rows, n_features), dtype=np.float64)         # array to hold feature values\n",
    "    \n",
    "    LA_HB_a_b = np.zeros((lob_data.shape[0]+1, 4), dtype = np.float64)  # array holding the LOASK, HIBID,\n",
    "                                                                        # alpha, beta, values \n",
    "\n",
    "    for i in prange(lob_data.shape[0]):                                 # iterates over the LOB to fill\n",
    "        row = lob_data[i]                                               # LA_HB_a_b values\n",
    "        \n",
    "        neg_ind = np.where(row < 0)[0]                                  # locate bid and ask prices (indicies)\n",
    "        pos_ind = np.where(row > 0)[0]\n",
    "        \n",
    "        if len(neg_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][1] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][1] = max(neg_ind) + 1 \n",
    "\n",
    "        if len(pos_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][0] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][0] = min(pos_ind) + 1\n",
    "\n",
    "        mid_price = (LA_HB_a_b[i][0] + LA_HB_a_b[i][1]) / 2             # calculate mid_price for alpha/beta calculations\n",
    "\n",
    "        if np.isnan(mid_price):\n",
    "            alpha = np.nan\n",
    "            beta = np.nan\n",
    "        else:                                                           # calculate alpha/beta using ab_weight var\n",
    "            beta = 0\n",
    "            for ind in neg_ind:\n",
    "                beta += (-1 * row[ind]) / ((mid_price - (ind + 1)) + ab_weight)\n",
    "    \n",
    "            alpha = 0\n",
    "            for ind in pos_ind:\n",
    "                alpha += row[ind] / (((ind + 1) - mid_price) + ab_weight)\n",
    "                \n",
    "\n",
    "        LA_HB_a_b[i][2] = alpha\n",
    "        LA_HB_a_b[i][3] = beta\n",
    "        \n",
    "    max_lob = lob_data.shape[0] - 1                                      # define max indicies for lob\n",
    "    max_tapes = tapes.shape[0] - 1                                       # define max indicies for tapes\n",
    "    \n",
    "    start_time = 0                                                       # define start time\n",
    "    lob_start = 0                                                        # define start index for lob\n",
    "    tapes_start = 0                                                      # define start index for tapes\n",
    "    \n",
    "    cas = np.zeros(800, dtype = np.int16)                                # define an array to hold CAS values\n",
    "    cbs = np.zeros(800, dtype = np.int16)                                # define an array to hold CBS values\n",
    "    for row_i in range(n_rows):\n",
    "        end_time = start_time + time_step_s                              # move to next time step\n",
    "        lob_end = lob_start\n",
    "        tapes_end = tapes_start\n",
    "\n",
    "        # get lob end index\n",
    "        while lob_times[lob_end] < end_time and lob_end < max_lob:       # move lob indicies to end time\n",
    "            lob_end += 1\n",
    "        \n",
    "        # get tapes end index\n",
    "        while tapes[tapes_end][0] < end_time and tapes_end < max_tapes:  # move tapes indicies to end time\n",
    "            tapes_end += 1\n",
    "\n",
    "        # feature calculations\n",
    "        if tapes_start == tapes_end:                                     # if there is no tapes data\n",
    "            AP = np.nan                                                  # set tapes features to np.nan\n",
    "            VOL = np.nan\n",
    "            PSTD = np.nan\n",
    "            nUoD = np.nan\n",
    "        else:\n",
    "            tapes_slice = tapes[tapes_start:tapes_end]                   # extract tapes slice, calculate AP, VOL\n",
    "            tapes_list = []\n",
    "            \n",
    "            for row in tapes_slice:\n",
    "                for _ in range(int(row[2])):\n",
    "                    tapes_list.append(row[1])\n",
    "\n",
    "            tapes_list = np.array(tapes_list, dtype=np.int32)\n",
    "            AP = np.mean(tapes_list)\n",
    "            VOL = np.sum(tapes_slice[:,2])\n",
    "            PSTD = np.std(tapes_list)\n",
    "\n",
    "            tapes_price_diff = tapes_slice[:,1][1:] - tapes_slice[:,1][:-1]\n",
    "            n_ups = np.sum(tapes_price_diff > 0)\n",
    "            n_downs = np.sum(tapes_price_diff < 0)\n",
    "            nUoD = (n_ups + 1) / (n_downs + 1) - 1\n",
    "\n",
    "        if lob_start == lob_end:                                         # if there is no LOB data\n",
    "            MP = np.nan                                                  # set lob features to np.nan\n",
    "            HIBID = np.nan\n",
    "            LOASK = np.nan\n",
    "            SPREAD = np.nan\n",
    "            TCBS = np.nan\n",
    "            TCAS = np.nan\n",
    "            WBP = np.nan\n",
    "            WAP = np.nan\n",
    "            AWS = np.nan\n",
    "            ALPHA = np.nan\n",
    "            BETA = np.nan\n",
    "            ZETA = np.nan  \n",
    "        else:\n",
    "            lob_slice = lob_data[lob_start:lob_end]                       # extract slices of data \n",
    "            LA_HB_a_b_slice = LA_HB_a_b[lob_start:lob_end]                \n",
    "\n",
    "            # midprice_calcs, alpha, beta\n",
    "            if median:                                                    # calculate price features\n",
    "                HIBID = np.median(LA_HB_a_b_slice[:,1])                   # using median if set to true\n",
    "                LOASK = np.median(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.median(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.median(LA_HB_a_b_slice[:,3])\n",
    "            else:\n",
    "                HIBID = np.nanmean(LA_HB_a_b_slice[:,1])\n",
    "                LOASK = np.nanmean(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.nanmean(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.nanmean(LA_HB_a_b_slice[:,3])\n",
    "\n",
    "            MP = (HIBID + LOASK) / 2\n",
    "            SPREAD = LOASK - HIBID\n",
    "            ZETA = BETA - ALPHA\n",
    "\n",
    "            if HIBID >= LOASK:\n",
    "                print(\"WARNING: HIBID >= LOASK\")\n",
    "\n",
    "            # consolidated calcs\n",
    "            cas[:] = 0                                                      # reset cas, cbs arrays for new data\n",
    "            cbs[:] = 0 \n",
    "\n",
    "            window_index = np.where(window_data[:,0] == end_time)[0]\n",
    "            if len(window_index) == 1:\n",
    "                w_bid = window_data[window_index[0], 4]\n",
    "                w_ask = window_data[window_index[0], 5]\n",
    "                LOWIN = window_data[window_index[0], 1]\n",
    "                HIWIN = window_data[window_index[0], 2]\n",
    "            else:\n",
    "                w_bid = MP - 100\n",
    "                w_ask = MP + 100\n",
    "                LOWIN = 0\n",
    "                HIWIN = 0\n",
    "\n",
    "            for ci in prange(int(np.floor(w_bid) - 1), int(np.ceil(w_ask) + 2)):\n",
    "                # can optimise with LOASK AND HIBID here\n",
    "                                                                        # only calculate cbs between window left of MP\n",
    "                cbs_vec = lob_slice[:,ci].copy() * -1                   # and less than LOASK + 100 for efficiency\n",
    "                cbs_vec[cbs_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cbs[ci] = np.sum(np.abs(np.diff(cbs_vec))) + cbs_vec[0]\n",
    "\n",
    "                                                                        # only calculate cas between window right of MP\n",
    "                cas_vec = lob_slice[:,ci].copy()                        # and greater than HIBID - 100 for efficiency\n",
    "                cas_vec[cas_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cas[ci] = np.sum(np.abs(np.diff(cas_vec))) + cas_vec[0]\n",
    "\n",
    "            TCBS = np.sum(cbs)                                              # Total CBS\n",
    "            TCAS = np.sum(cas)                                              # Total CAS\n",
    "\n",
    "            if TCBS == 0:                                                   # Calculate WBP, np.nan if no activity\n",
    "                WBP = np.nan\n",
    "            else:\n",
    "                WBP = 0\n",
    "                for ci in prange(800):\n",
    "                    WBP += (ci + 1) * (cbs[ci] / TCBS)\n",
    "\n",
    "            if TCAS == 0:                                                   # Calculate WAP, np.nan if no activity\n",
    "                WAP = np.nan\n",
    "            else:\n",
    "                WAP = 0\n",
    "                for ci in prange(800):\n",
    "                    WAP += (ci + 1) * (cas[ci] / TCAS)\n",
    "\n",
    "            AWS = WAP - WBP                                                 # Activity weighted spread calc\n",
    "\n",
    "        # feature setting\n",
    "        feat_arr[row_i][features.index(\"AP\")] = AP                          # set the values to the feat_arr\n",
    "        feat_arr[row_i][features.index(\"VOL\")] = VOL\n",
    "        feat_arr[row_i][features.index(\"MP\")] = MP\n",
    "        feat_arr[row_i][features.index(\"HIBID\")] = HIBID\n",
    "        feat_arr[row_i][features.index(\"LOASK\")] = LOASK\n",
    "        feat_arr[row_i][features.index(\"SPREAD\")] = SPREAD\n",
    "        feat_arr[row_i][features.index(\"TCAS\")] = TCAS\n",
    "        feat_arr[row_i][features.index(\"TCBS\")] = TCBS\n",
    "        feat_arr[row_i][features.index(\"WAP\")] = WAP\n",
    "        feat_arr[row_i][features.index(\"WBP\")] = WBP\n",
    "        feat_arr[row_i][features.index(\"AWS\")] = AWS\n",
    "        feat_arr[row_i][features.index(\"ALPHA\")] = ALPHA\n",
    "        feat_arr[row_i][features.index(\"BETA\")] = BETA\n",
    "        feat_arr[row_i][features.index(\"ZETA\")] = ZETA\n",
    "        feat_arr[row_i][features.index(\"GAP\")] = MP - AP\n",
    "        feat_arr[row_i][features.index(\"ENDT\")] = end_time\n",
    "        feat_arr[row_i][features.index(\"PSTD\")] = PSTD\n",
    "        feat_arr[row_i][features.index(\"LOWIN\")] = LOWIN\n",
    "        feat_arr[row_i][features.index(\"HIWIN\")] = HIWIN\n",
    "        feat_arr[row_i][features.index(\"nUoD\")] = nUoD\n",
    "\n",
    "\n",
    "        # adjust start times\n",
    "        start_time = end_time                                                # Set the next start times and \n",
    "        lob_start = lob_end                                                  # indicies to the last end times / indicies\n",
    "        tapes_start = tapes_end\n",
    "\n",
    "    return feat_arr, features\n",
    "\n",
    "for lob, lob_times, tapes in data:\n",
    "    outside, w_bids, w_asks = get_tapes_window(tapes)\n",
    "    window_data = np.zeros((len(outside), 6), dtype = float)\n",
    "    for i in range(len(outside)):\n",
    "        window_data[i][:4] = outside[i]\n",
    "        window_data[i][4] = w_bids[i]\n",
    "        window_data[i][5] = w_asks[i]\n",
    "\n",
    "    features = get_features(lob, lob_times, tapes, 60, window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>HIBID</th>\n",
       "      <th>LOASK</th>\n",
       "      <th>AP</th>\n",
       "      <th>WBP</th>\n",
       "      <th>WAP</th>\n",
       "      <th>TCBS</th>\n",
       "      <th>TCAS</th>\n",
       "      <th>AWS</th>\n",
       "      <th>VOL</th>\n",
       "      <th>...</th>\n",
       "      <th>ALPHA</th>\n",
       "      <th>BETA</th>\n",
       "      <th>ZETA</th>\n",
       "      <th>ENDT</th>\n",
       "      <th>PSTD</th>\n",
       "      <th>LOWIN</th>\n",
       "      <th>HIWIN</th>\n",
       "      <th>nUoD</th>\n",
       "      <th>WMP</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.0</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>286.035800</td>\n",
       "      <td>279.601927</td>\n",
       "      <td>292.469674</td>\n",
       "      <td>281.560707</td>\n",
       "      <td>270.956016</td>\n",
       "      <td>292.588977</td>\n",
       "      <td>1018.898039</td>\n",
       "      <td>666.282353</td>\n",
       "      <td>21.632961</td>\n",
       "      <td>94.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>1.841453</td>\n",
       "      <td>3.452572</td>\n",
       "      <td>1.611119</td>\n",
       "      <td>15330.000000</td>\n",
       "      <td>3.833884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>-0.096779</td>\n",
       "      <td>281.772496</td>\n",
       "      <td>0.045467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.977415</td>\n",
       "      <td>12.768949</td>\n",
       "      <td>14.883389</td>\n",
       "      <td>11.893899</td>\n",
       "      <td>15.788646</td>\n",
       "      <td>12.656252</td>\n",
       "      <td>349.558112</td>\n",
       "      <td>208.358263</td>\n",
       "      <td>15.750608</td>\n",
       "      <td>14.595335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511057</td>\n",
       "      <td>1.002793</td>\n",
       "      <td>0.920204</td>\n",
       "      <td>8842.115132</td>\n",
       "      <td>0.726250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640589</td>\n",
       "      <td>0.248906</td>\n",
       "      <td>11.946155</td>\n",
       "      <td>8.318084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>250.568493</td>\n",
       "      <td>233.357496</td>\n",
       "      <td>253.757991</td>\n",
       "      <td>251.489796</td>\n",
       "      <td>224.682692</td>\n",
       "      <td>259.973251</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>4.542830</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538498</td>\n",
       "      <td>0.746761</td>\n",
       "      <td>-1.015538</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.103878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.647059</td>\n",
       "      <td>248.004464</td>\n",
       "      <td>-33.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>279.929176</td>\n",
       "      <td>273.170215</td>\n",
       "      <td>286.403618</td>\n",
       "      <td>274.895143</td>\n",
       "      <td>262.511816</td>\n",
       "      <td>286.031861</td>\n",
       "      <td>779.250000</td>\n",
       "      <td>511.250000</td>\n",
       "      <td>12.292414</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507612</td>\n",
       "      <td>2.771704</td>\n",
       "      <td>0.978558</td>\n",
       "      <td>7695.000000</td>\n",
       "      <td>3.281932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276515</td>\n",
       "      <td>274.555338</td>\n",
       "      <td>-3.363210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289.214136</td>\n",
       "      <td>284.755665</td>\n",
       "      <td>292.735047</td>\n",
       "      <td>286.552222</td>\n",
       "      <td>278.311070</td>\n",
       "      <td>294.445186</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>660.500000</td>\n",
       "      <td>14.633301</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891684</td>\n",
       "      <td>3.474120</td>\n",
       "      <td>1.540967</td>\n",
       "      <td>15330.000000</td>\n",
       "      <td>3.803233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>286.671618</td>\n",
       "      <td>-0.538160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>293.223540</td>\n",
       "      <td>288.399743</td>\n",
       "      <td>297.924144</td>\n",
       "      <td>289.620837</td>\n",
       "      <td>282.220354</td>\n",
       "      <td>298.825185</td>\n",
       "      <td>1206.750000</td>\n",
       "      <td>806.750000</td>\n",
       "      <td>18.044078</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188950</td>\n",
       "      <td>4.014576</td>\n",
       "      <td>2.153808</td>\n",
       "      <td>22965.000000</td>\n",
       "      <td>4.322434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>289.768441</td>\n",
       "      <td>2.956135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>319.129438</td>\n",
       "      <td>298.309117</td>\n",
       "      <td>348.053254</td>\n",
       "      <td>298.530000</td>\n",
       "      <td>291.897314</td>\n",
       "      <td>337.056834</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>76.150552</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.473525</td>\n",
       "      <td>7.030652</td>\n",
       "      <td>5.084442</td>\n",
       "      <td>30600.000000</td>\n",
       "      <td>6.094415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>303.925951</td>\n",
       "      <td>37.173961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MP       HIBID       LOASK          AP         WBP         WAP  \\\n",
       "count  510.000000  510.000000  510.000000  510.000000  510.000000  510.000000   \n",
       "mean   286.035800  279.601927  292.469674  281.560707  270.956016  292.588977   \n",
       "std     11.977415   12.768949   14.883389   11.893899   15.788646   12.656252   \n",
       "min    250.568493  233.357496  253.757991  251.489796  224.682692  259.973251   \n",
       "25%    279.929176  273.170215  286.403618  274.895143  262.511816  286.031861   \n",
       "50%    289.214136  284.755665  292.735047  286.552222  278.311070  294.445186   \n",
       "75%    293.223540  288.399743  297.924144  289.620837  282.220354  298.825185   \n",
       "max    319.129438  298.309117  348.053254  298.530000  291.897314  337.056834   \n",
       "\n",
       "              TCBS         TCAS         AWS         VOL  ...       ALPHA  \\\n",
       "count   510.000000   510.000000  510.000000  510.000000  ...  510.000000   \n",
       "mean   1018.898039   666.282353   21.632961   94.060784  ...    1.841453   \n",
       "std     349.558112   208.358263   15.750608   14.595335  ...    0.511057   \n",
       "min     204.000000   202.000000    4.542830   54.000000  ...    0.538498   \n",
       "25%     779.250000   511.250000   12.292414   83.000000  ...    1.507612   \n",
       "50%     963.000000   660.500000   14.633301   94.000000  ...    1.891684   \n",
       "75%    1206.750000   806.750000   18.044078  104.000000  ...    2.188950   \n",
       "max    2479.000000  1275.000000   76.150552  140.000000  ...    3.473525   \n",
       "\n",
       "             BETA        ZETA          ENDT        PSTD  LOWIN       HIWIN  \\\n",
       "count  510.000000  510.000000    510.000000  510.000000  510.0  510.000000   \n",
       "mean     3.452572    1.611119  15330.000000    3.833884    0.0    0.047059   \n",
       "std      1.002793    0.920204   8842.115132    0.726250    0.0    0.640589   \n",
       "min      0.746761   -1.015538     60.000000    2.103878    0.0    0.000000   \n",
       "25%      2.771704    0.978558   7695.000000    3.281932    0.0    0.000000   \n",
       "50%      3.474120    1.540967  15330.000000    3.803233    0.0    0.000000   \n",
       "75%      4.014576    2.153808  22965.000000    4.322434    0.0    0.000000   \n",
       "max      7.030652    5.084442  30600.000000    6.094415    0.0   12.000000   \n",
       "\n",
       "             nUoD         WMP  MP_diff(y)  \n",
       "count  510.000000  510.000000  509.000000  \n",
       "mean    -0.096779  281.772496    0.045467  \n",
       "std      0.248906   11.946155    8.318084  \n",
       "min     -0.647059  248.004464  -33.640400  \n",
       "25%     -0.276515  274.555338   -3.363210  \n",
       "50%     -0.133333  286.671618   -0.538160  \n",
       "75%      0.052632  289.768441    2.956135  \n",
       "max      0.916667  303.925951   37.173961  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(features[0], columns = features[1])\n",
    "df[\"WMP\"] = (df[\"WBP\"] + df[\"WAP\"]) / 2\n",
    "df[\"MP_diff(y)\"] = df[\"MP\"].diff(1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>HIBID</th>\n",
       "      <th>LOASK</th>\n",
       "      <th>AP</th>\n",
       "      <th>WBP</th>\n",
       "      <th>WAP</th>\n",
       "      <th>TCBS</th>\n",
       "      <th>TCAS</th>\n",
       "      <th>AWS</th>\n",
       "      <th>VOL</th>\n",
       "      <th>...</th>\n",
       "      <th>ALPHA</th>\n",
       "      <th>BETA</th>\n",
       "      <th>ZETA</th>\n",
       "      <th>ENDT</th>\n",
       "      <th>PSTD</th>\n",
       "      <th>LOWIN</th>\n",
       "      <th>HIWIN</th>\n",
       "      <th>nUoD</th>\n",
       "      <th>WMP</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.814778</td>\n",
       "      <td>259.788018</td>\n",
       "      <td>271.841538</td>\n",
       "      <td>262.029851</td>\n",
       "      <td>236.790535</td>\n",
       "      <td>282.000831</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>45.210295</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.546072</td>\n",
       "      <td>3.598042</td>\n",
       "      <td>1.051970</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.088463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>259.395683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260.504993</td>\n",
       "      <td>258.206847</td>\n",
       "      <td>262.803138</td>\n",
       "      <td>260.669811</td>\n",
       "      <td>228.672641</td>\n",
       "      <td>279.127962</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>50.455321</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.190554</td>\n",
       "      <td>3.261417</td>\n",
       "      <td>1.070863</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.985165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>253.900302</td>\n",
       "      <td>-5.309786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>265.263047</td>\n",
       "      <td>262.929478</td>\n",
       "      <td>267.596615</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>235.558824</td>\n",
       "      <td>282.310867</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>46.752043</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.830815</td>\n",
       "      <td>4.571049</td>\n",
       "      <td>2.740233</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.990622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>258.934845</td>\n",
       "      <td>4.758054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264.908689</td>\n",
       "      <td>262.751105</td>\n",
       "      <td>267.066274</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>242.977695</td>\n",
       "      <td>280.393509</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>37.415814</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.584140</td>\n",
       "      <td>4.643347</td>\n",
       "      <td>2.059208</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.106632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>261.685602</td>\n",
       "      <td>-0.354357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265.717914</td>\n",
       "      <td>263.077540</td>\n",
       "      <td>268.358289</td>\n",
       "      <td>263.102564</td>\n",
       "      <td>240.495146</td>\n",
       "      <td>281.827652</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>41.332506</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.311307</td>\n",
       "      <td>3.945691</td>\n",
       "      <td>1.634385</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.299533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>261.161399</td>\n",
       "      <td>0.809225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>290.823338</td>\n",
       "      <td>287.748370</td>\n",
       "      <td>293.898305</td>\n",
       "      <td>289.822917</td>\n",
       "      <td>262.212719</td>\n",
       "      <td>310.930890</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>48.718171</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.032066</td>\n",
       "      <td>2.435379</td>\n",
       "      <td>0.403314</td>\n",
       "      <td>30360.0</td>\n",
       "      <td>5.228119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>286.571805</td>\n",
       "      <td>-2.472854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>304.298425</td>\n",
       "      <td>293.325984</td>\n",
       "      <td>315.270866</td>\n",
       "      <td>293.675000</td>\n",
       "      <td>275.660162</td>\n",
       "      <td>316.156391</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>40.496229</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295897</td>\n",
       "      <td>4.784250</td>\n",
       "      <td>3.488353</td>\n",
       "      <td>30420.0</td>\n",
       "      <td>2.178159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>295.908276</td>\n",
       "      <td>13.475088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>295.507225</td>\n",
       "      <td>286.226879</td>\n",
       "      <td>304.787572</td>\n",
       "      <td>289.133333</td>\n",
       "      <td>262.505993</td>\n",
       "      <td>310.785872</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>48.279879</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.425354</td>\n",
       "      <td>2.391568</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>30480.0</td>\n",
       "      <td>4.485037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>286.645933</td>\n",
       "      <td>-8.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>292.192044</td>\n",
       "      <td>289.196159</td>\n",
       "      <td>295.187929</td>\n",
       "      <td>290.021277</td>\n",
       "      <td>263.860664</td>\n",
       "      <td>312.310627</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>48.449963</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.183961</td>\n",
       "      <td>3.156712</td>\n",
       "      <td>0.972751</td>\n",
       "      <td>30540.0</td>\n",
       "      <td>3.448647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>288.085645</td>\n",
       "      <td>-3.315182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>288.957534</td>\n",
       "      <td>286.119178</td>\n",
       "      <td>291.795890</td>\n",
       "      <td>288.635294</td>\n",
       "      <td>256.594708</td>\n",
       "      <td>306.591656</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>49.996949</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.541774</td>\n",
       "      <td>2.916821</td>\n",
       "      <td>1.375047</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>4.389418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>281.593182</td>\n",
       "      <td>-3.234510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MP       HIBID       LOASK          AP         WBP         WAP  \\\n",
       "0    265.814778  259.788018  271.841538  262.029851  236.790535  282.000831   \n",
       "1    260.504993  258.206847  262.803138  260.669811  228.672641  279.127962   \n",
       "2    265.263047  262.929478  267.596615  264.000000  235.558824  282.310867   \n",
       "3    264.908689  262.751105  267.066274  263.000000  242.977695  280.393509   \n",
       "4    265.717914  263.077540  268.358289  263.102564  240.495146  281.827652   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "505  290.823338  287.748370  293.898305  289.822917  262.212719  310.930890   \n",
       "506  304.298425  293.325984  315.270866  293.675000  275.660162  316.156391   \n",
       "507  295.507225  286.226879  304.787572  289.133333  262.505993  310.785872   \n",
       "508  292.192044  289.196159  295.187929  290.021277  263.860664  312.310627   \n",
       "509  288.957534  286.119178  291.795890  288.635294  256.594708  306.591656   \n",
       "\n",
       "       TCBS    TCAS        AWS    VOL  ...     ALPHA      BETA      ZETA  \\\n",
       "0    1289.0  1204.0  45.210295   67.0  ...  2.546072  3.598042  1.051970   \n",
       "1    1897.0   844.0  50.455321  106.0  ...  2.190554  3.261417  1.070863   \n",
       "2    1768.0   727.0  46.752043   89.0  ...  1.830815  4.571049  2.740233   \n",
       "3    1345.0   986.0  37.415814   86.0  ...  2.584140  4.643347  2.059208   \n",
       "4    1442.0  1056.0  41.332506   78.0  ...  2.311307  3.945691  1.634385   \n",
       "..      ...     ...        ...    ...  ...       ...       ...       ...   \n",
       "505  1368.0   955.0  48.718171   96.0  ...  2.032066  2.435379  0.403314   \n",
       "506  1486.0   665.0  40.496229   80.0  ...  1.295897  4.784250  3.488353   \n",
       "507  1168.0   906.0  48.279879  105.0  ...  1.425354  2.391568  0.966214   \n",
       "508  1055.0  1101.0  48.449963   94.0  ...  2.183961  3.156712  0.972751   \n",
       "509  2154.0   791.0  49.996949   85.0  ...  1.541774  2.916821  1.375047   \n",
       "\n",
       "        ENDT      PSTD  LOWIN  HIWIN      nUoD         WMP  MP_diff(y)  \n",
       "0       60.0  4.088463    0.0    0.0 -0.500000  259.395683         NaN  \n",
       "1      120.0  3.985165    0.0    0.0  0.437500  253.900302   -5.309786  \n",
       "2      180.0  2.990622    0.0    0.0 -0.235294  258.934845    4.758054  \n",
       "3      240.0  3.106632    0.0    0.0 -0.550000  261.685602   -0.354357  \n",
       "4      300.0  3.299533    0.0    0.0  0.000000  261.161399    0.809225  \n",
       "..       ...       ...    ...    ...       ...         ...         ...  \n",
       "505  30360.0  5.228119    0.0    0.0  0.111111  286.571805   -2.472854  \n",
       "506  30420.0  2.178159    0.0    0.0  0.000000  295.908276   13.475088  \n",
       "507  30480.0  4.485037    0.0    0.0 -0.125000  286.645933   -8.791200  \n",
       "508  30540.0  3.448647    0.0    0.0  0.062500  288.085645   -3.315182  \n",
       "509  30600.0  4.389418    0.0    0.0  0.166667  281.593182   -3.234510  \n",
       "\n",
       "[510 rows x 22 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from LOB and Tapes\n",
    "\n",
    "get mean, std, trend, delta from 60 min segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCAS_std</th>\n",
       "      <th>TCAS_mean</th>\n",
       "      <th>TCAS_delta</th>\n",
       "      <th>TCBS_std</th>\n",
       "      <th>TCBS_mean</th>\n",
       "      <th>TCBS_delta</th>\n",
       "      <th>ALPHA_std</th>\n",
       "      <th>ALPHA_mean</th>\n",
       "      <th>ALPHA_delta</th>\n",
       "      <th>BETA_std</th>\n",
       "      <th>...</th>\n",
       "      <th>GAP_delta</th>\n",
       "      <th>nUoD_std</th>\n",
       "      <th>nUoD_mean</th>\n",
       "      <th>nUoD_delta</th>\n",
       "      <th>PSTD_std</th>\n",
       "      <th>PSTD_mean</th>\n",
       "      <th>PSTD_delta</th>\n",
       "      <th>LOWIN_sum</th>\n",
       "      <th>HIWIN_sum</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENDT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3660.0</th>\n",
       "      <td>170.659358</td>\n",
       "      <td>778.983333</td>\n",
       "      <td>-800.0</td>\n",
       "      <td>442.372433</td>\n",
       "      <td>1341.216667</td>\n",
       "      <td>-818.0</td>\n",
       "      <td>0.659799</td>\n",
       "      <td>1.567495</td>\n",
       "      <td>-1.176586</td>\n",
       "      <td>1.014749</td>\n",
       "      <td>...</td>\n",
       "      <td>25.799518</td>\n",
       "      <td>0.276989</td>\n",
       "      <td>-0.128074</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.731317</td>\n",
       "      <td>3.804950</td>\n",
       "      <td>-0.083088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.289241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720.0</th>\n",
       "      <td>174.518559</td>\n",
       "      <td>763.150000</td>\n",
       "      <td>-590.0</td>\n",
       "      <td>451.720495</td>\n",
       "      <td>1330.166667</td>\n",
       "      <td>-1271.0</td>\n",
       "      <td>0.657178</td>\n",
       "      <td>1.536192</td>\n",
       "      <td>-1.522655</td>\n",
       "      <td>1.027195</td>\n",
       "      <td>...</td>\n",
       "      <td>35.976862</td>\n",
       "      <td>0.274198</td>\n",
       "      <td>-0.118074</td>\n",
       "      <td>-0.337500</td>\n",
       "      <td>0.732061</td>\n",
       "      <td>3.806590</td>\n",
       "      <td>0.201702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780.0</th>\n",
       "      <td>177.742463</td>\n",
       "      <td>757.183333</td>\n",
       "      <td>-241.0</td>\n",
       "      <td>449.843317</td>\n",
       "      <td>1312.583333</td>\n",
       "      <td>-926.0</td>\n",
       "      <td>0.655731</td>\n",
       "      <td>1.534631</td>\n",
       "      <td>0.266062</td>\n",
       "      <td>1.045622</td>\n",
       "      <td>...</td>\n",
       "      <td>3.591287</td>\n",
       "      <td>0.264489</td>\n",
       "      <td>-0.127638</td>\n",
       "      <td>0.098930</td>\n",
       "      <td>0.744742</td>\n",
       "      <td>3.821635</td>\n",
       "      <td>1.897251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.205879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840.0</th>\n",
       "      <td>179.022016</td>\n",
       "      <td>754.866667</td>\n",
       "      <td>-398.0</td>\n",
       "      <td>446.806364</td>\n",
       "      <td>1301.200000</td>\n",
       "      <td>-260.0</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>1.537593</td>\n",
       "      <td>-0.575570</td>\n",
       "      <td>1.047074</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.286608</td>\n",
       "      <td>0.267390</td>\n",
       "      <td>-0.120384</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.746150</td>\n",
       "      <td>3.851016</td>\n",
       "      <td>1.646833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900.0</th>\n",
       "      <td>177.673752</td>\n",
       "      <td>748.266667</td>\n",
       "      <td>-466.0</td>\n",
       "      <td>447.086825</td>\n",
       "      <td>1298.266667</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>0.643931</td>\n",
       "      <td>1.523878</td>\n",
       "      <td>-0.550086</td>\n",
       "      <td>1.127842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282176</td>\n",
       "      <td>0.261567</td>\n",
       "      <td>-0.112197</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.742758</td>\n",
       "      <td>3.855054</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.920985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30360.0</th>\n",
       "      <td>178.205375</td>\n",
       "      <td>845.333333</td>\n",
       "      <td>166.0</td>\n",
       "      <td>333.649527</td>\n",
       "      <td>1385.400000</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.437973</td>\n",
       "      <td>1.764666</td>\n",
       "      <td>-0.143816</td>\n",
       "      <td>0.725498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>0.255992</td>\n",
       "      <td>-0.062002</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.779978</td>\n",
       "      <td>4.068622</td>\n",
       "      <td>-0.199249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.472854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30420.0</th>\n",
       "      <td>177.264425</td>\n",
       "      <td>850.083333</td>\n",
       "      <td>282.0</td>\n",
       "      <td>330.636499</td>\n",
       "      <td>1390.850000</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>1.765987</td>\n",
       "      <td>0.203721</td>\n",
       "      <td>0.718263</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.392612</td>\n",
       "      <td>0.255030</td>\n",
       "      <td>-0.055151</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.793661</td>\n",
       "      <td>4.090518</td>\n",
       "      <td>2.503863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.475088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480.0</th>\n",
       "      <td>177.400528</td>\n",
       "      <td>849.950000</td>\n",
       "      <td>-408.0</td>\n",
       "      <td>324.437518</td>\n",
       "      <td>1400.716667</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.442673</td>\n",
       "      <td>1.757113</td>\n",
       "      <td>-1.053919</td>\n",
       "      <td>0.749819</td>\n",
       "      <td>...</td>\n",
       "      <td>10.198971</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>-0.053960</td>\n",
       "      <td>-0.130435</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>4.081416</td>\n",
       "      <td>-2.842435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30540.0</th>\n",
       "      <td>175.175261</td>\n",
       "      <td>847.166667</td>\n",
       "      <td>505.0</td>\n",
       "      <td>308.584299</td>\n",
       "      <td>1410.283333</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.437838</td>\n",
       "      <td>1.741705</td>\n",
       "      <td>0.534358</td>\n",
       "      <td>0.755043</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.581689</td>\n",
       "      <td>0.254135</td>\n",
       "      <td>-0.058217</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.804730</td>\n",
       "      <td>4.072490</td>\n",
       "      <td>-0.085893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.315182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30600.0</th>\n",
       "      <td>168.244977</td>\n",
       "      <td>858.833333</td>\n",
       "      <td>684.0</td>\n",
       "      <td>299.911618</td>\n",
       "      <td>1415.433333</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.427125</td>\n",
       "      <td>1.763255</td>\n",
       "      <td>1.010516</td>\n",
       "      <td>0.734488</td>\n",
       "      <td>...</td>\n",
       "      <td>3.183088</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>-0.057176</td>\n",
       "      <td>0.216346</td>\n",
       "      <td>0.805969</td>\n",
       "      <td>4.053786</td>\n",
       "      <td>-0.872413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.234510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TCAS_std   TCAS_mean  TCAS_delta    TCBS_std    TCBS_mean  \\\n",
       "ENDT                                                                   \n",
       "3660.0   170.659358  778.983333      -800.0  442.372433  1341.216667   \n",
       "3720.0   174.518559  763.150000      -590.0  451.720495  1330.166667   \n",
       "3780.0   177.742463  757.183333      -241.0  449.843317  1312.583333   \n",
       "3840.0   179.022016  754.866667      -398.0  446.806364  1301.200000   \n",
       "3900.0   177.673752  748.266667      -466.0  447.086825  1298.266667   \n",
       "...             ...         ...         ...         ...          ...   \n",
       "30360.0  178.205375  845.333333       166.0  333.649527  1385.400000   \n",
       "30420.0  177.264425  850.083333       282.0  330.636499  1390.850000   \n",
       "30480.0  177.400528  849.950000      -408.0  324.437518  1400.716667   \n",
       "30540.0  175.175261  847.166667       505.0  308.584299  1410.283333   \n",
       "30600.0  168.244977  858.833333       684.0  299.911618  1415.433333   \n",
       "\n",
       "         TCBS_delta  ALPHA_std  ALPHA_mean  ALPHA_delta  BETA_std  ...  \\\n",
       "ENDT                                                               ...   \n",
       "3660.0       -818.0   0.659799    1.567495    -1.176586  1.014749  ...   \n",
       "3720.0      -1271.0   0.657178    1.536192    -1.522655  1.027195  ...   \n",
       "3780.0       -926.0   0.655731    1.534631     0.266062  1.045622  ...   \n",
       "3840.0       -260.0   0.657462    1.537593    -0.575570  1.047074  ...   \n",
       "3900.0       -273.0   0.643931    1.523878    -0.550086  1.127842  ...   \n",
       "...             ...        ...         ...          ...       ...  ...   \n",
       "30360.0       915.0   0.437973    1.764666    -0.143816  0.725498  ...   \n",
       "30420.0       474.0   0.438657    1.765987     0.203721  0.718263  ...   \n",
       "30480.0       892.0   0.442673    1.757113    -1.053919  0.749819  ...   \n",
       "30540.0       422.0   0.437838    1.741705     0.534358  0.755043  ...   \n",
       "30600.0       463.0   0.427125    1.763255     1.010516  0.734488  ...   \n",
       "\n",
       "         GAP_delta  nUoD_std  nUoD_mean  nUoD_delta  PSTD_std  PSTD_mean  \\\n",
       "ENDT                                                                       \n",
       "3660.0   25.799518  0.276989  -0.128074    0.180000  0.731317   3.804950   \n",
       "3720.0   35.976862  0.274198  -0.118074   -0.337500  0.732061   3.806590   \n",
       "3780.0    3.591287  0.264489  -0.127638    0.098930  0.744742   3.821635   \n",
       "3840.0   -2.286608  0.267390  -0.120384    0.750000  0.746150   3.851016   \n",
       "3900.0    0.282176  0.261567  -0.112197   -0.058824  0.742758   3.855054   \n",
       "...            ...       ...        ...         ...       ...        ...   \n",
       "30360.0   0.227716  0.255992  -0.062002    0.355556  0.779978   4.068622   \n",
       "30420.0  -1.392612  0.255030  -0.055151    0.182540  0.793661   4.090518   \n",
       "30480.0  10.198971  0.255118  -0.053960   -0.130435  0.812192   4.081416   \n",
       "30540.0 -21.581689  0.254135  -0.058217   -0.125000  0.804730   4.072490   \n",
       "30600.0   3.183088  0.254499  -0.057176    0.216346  0.805969   4.053786   \n",
       "\n",
       "         PSTD_delta  LOWIN_sum  HIWIN_sum  MP_diff(y)  \n",
       "ENDT                                                   \n",
       "3660.0    -0.083088        0.0        0.0    8.289241  \n",
       "3720.0     0.201702        0.0        0.0  -33.640400  \n",
       "3780.0     1.897251        0.0        0.0   -2.205879  \n",
       "3840.0     1.646833        0.0        0.0    7.905300  \n",
       "3900.0     0.049430        0.0        0.0   -2.920985  \n",
       "...             ...        ...        ...         ...  \n",
       "30360.0   -0.199249        0.0        1.0   -2.472854  \n",
       "30420.0    2.503863        0.0        1.0   13.475088  \n",
       "30480.0   -2.842435        0.0        0.0   -8.791200  \n",
       "30540.0   -0.085893        0.0        0.0   -3.315182  \n",
       "30600.0   -0.872413        0.0        0.0   -3.234510  \n",
       "\n",
       "[450 rows x 36 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "features = [\"TCAS\", \"TCBS\", \"ALPHA\", \"BETA\", \"ZETA\",\n",
    "            \"WMP\", \"AWS\", \"VOL\", \"GAP\", \"nUoD\", \"PSTD\"]\n",
    "\n",
    "sum_features = [\"LOWIN\", \"HIWIN\"]\n",
    "\n",
    "y_feat = \"MP_diff(y)\"\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df) - 60):\n",
    "    train_segment = df[i:i+60]\n",
    "    test_segment = df[i+60:i+61]\n",
    "\n",
    "    row = {}\n",
    "    for f in features:\n",
    "        # std\n",
    "        row[f+\"_std\"] = np.std(train_segment[f])\n",
    "        # mean\n",
    "        row[f+\"_mean\"] = np.mean(train_segment[f])\n",
    "        # delta\n",
    "        row[f+\"_delta\"] = train_segment[f].iloc[-1] - train_segment[f].iloc[0]\n",
    "        # trend\n",
    "        # ####### # # #  do this\n",
    "\n",
    "    for f in sum_features:\n",
    "        row[f+\"_sum\"] = np.sum(train_segment[f])\n",
    "\n",
    "    row[y_feat] = test_segment[y_feat].iloc[0]\n",
    "\n",
    "    X_df = pd.concat([X_df, pd.DataFrame(row, index = test_segment[\"ENDT\"])])\n",
    "\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = list(X_df)\n",
    "x_features.remove(y_feat)\n",
    "\n",
    "X = X_df[x_features]\n",
    "y = X_df[y_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wwden\\OneDrive\\Documents\\GitHub\\dsmp-2024-group-19\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,529</span> (25.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,529\u001b[0m (25.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,529</span> (25.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,529\u001b[0m (25.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_regression_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu',input_shape=input_shape),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)  # Output layer with single neuron for regression\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "input_shape = (len(x_features),)\n",
    "regression_model = create_regression_model(input_shape)\n",
    "\n",
    "# Display model architecture\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X contains your input features and y contains your target values\n",
    "# X shape: (number of samples, 35)\n",
    "\n",
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5103 - val_loss: 4.9907\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7870 - val_loss: 5.1084\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9844 - val_loss: 5.1361\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5994 - val_loss: 5.1775\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9682 - val_loss: 5.0891\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2558 - val_loss: 5.0464\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8445 - val_loss: 4.8344\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0674 - val_loss: 4.8654\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2371 - val_loss: 4.7812\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6957 - val_loss: 4.7187\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7591 - val_loss: 4.7971\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5776 - val_loss: 4.8662\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3203 - val_loss: 4.8381\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6163 - val_loss: 4.9015\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.0350 - val_loss: 4.8655\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2279 - val_loss: 5.0043\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9538 - val_loss: 5.0267\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7609 - val_loss: 4.8970\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.3146 - val_loss: 4.7693\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6533 - val_loss: 5.1624\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9351 - val_loss: 4.6102\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5003 - val_loss: 4.7627\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2667 - val_loss: 4.9209\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2614 - val_loss: 4.7596\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1273 - val_loss: 4.8914\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2876 - val_loss: 4.7408\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2346 - val_loss: 4.9697\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2945 - val_loss: 5.2904\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8218 - val_loss: 4.8010\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1498 - val_loss: 4.8903\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9261 - val_loss: 5.4260\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0143 - val_loss: 5.1096\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0539 - val_loss: 5.1905\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8696 - val_loss: 5.0479\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5789 - val_loss: 5.1070\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7015 - val_loss: 5.2635\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7317 - val_loss: 5.1054\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8382 - val_loss: 5.1725\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5219 - val_loss: 5.4969\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6835 - val_loss: 5.0746\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7180 - val_loss: 5.2361\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5335 - val_loss: 5.2864\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5262 - val_loss: 5.2789\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7395 - val_loss: 5.5794\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4466 - val_loss: 5.4771\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3473 - val_loss: 5.4142\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4097 - val_loss: 5.4718\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2740 - val_loss: 5.5035\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4913 - val_loss: 5.4686\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4590 - val_loss: 5.5817\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3482 - val_loss: 5.7450\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2204 - val_loss: 5.4614\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3321 - val_loss: 5.5696\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3091 - val_loss: 5.7243\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2471 - val_loss: 5.5225\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3424 - val_loss: 5.4079\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2860 - val_loss: 5.3559\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4074 - val_loss: 5.8120\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0482 - val_loss: 5.7236\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0032 - val_loss: 5.8056\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1993 - val_loss: 5.7530\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0963 - val_loss: 5.5475\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0159 - val_loss: 5.6153\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9637 - val_loss: 5.6779\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0943 - val_loss: 5.7876\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0183 - val_loss: 5.6934\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1191 - val_loss: 5.6061\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1869 - val_loss: 5.6865\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9320 - val_loss: 5.7225\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1113 - val_loss: 5.6044\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9900 - val_loss: 5.5076\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9758 - val_loss: 5.6699\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0983 - val_loss: 6.0640\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0874 - val_loss: 5.4177\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0024 - val_loss: 5.5723\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0487 - val_loss: 5.7777\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9643 - val_loss: 5.6343\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9618 - val_loss: 5.7921\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0690 - val_loss: 5.8943\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9360 - val_loss: 5.6360\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9691 - val_loss: 5.6064\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0280 - val_loss: 5.6511\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9344 - val_loss: 5.5999\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9342 - val_loss: 5.7954\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8157 - val_loss: 5.5477\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9544 - val_loss: 5.8075\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8436 - val_loss: 5.4465\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0766 - val_loss: 5.5187\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0011 - val_loss: 5.9090\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8946 - val_loss: 5.5242\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9492 - val_loss: 5.8529\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0355 - val_loss: 5.6052\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9871 - val_loss: 5.4722\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8093 - val_loss: 5.7602\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9878 - val_loss: 5.5701\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9760 - val_loss: 5.4988\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8735 - val_loss: 5.9475\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9323 - val_loss: 5.9579\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8505 - val_loss: 5.8792\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8447 - val_loss: 5.7808\n"
     ]
    }
   ],
   "source": [
    "history = regression_model.fit(X_train_normalized, y_train, epochs=100, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0013 \n",
      "Test Loss: 5.921733856201172\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "test_loss = regression_model.evaluate(X_test_normalized, y_test)\n",
    "\n",
    "# Print the test loss\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features\n",
    "\n",
    "for use in models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
