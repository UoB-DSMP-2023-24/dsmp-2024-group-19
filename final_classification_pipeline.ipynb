{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tapes and lob data\n",
    "\n",
    "do this for each day otherwise memory (RAM) exceeds most computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "from fast_tools import get_data, get_data_gen\n",
    "\n",
    "#data = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "Remove outliers from lob and create an additional columns noting this\n",
    "\n",
    "FFill tapes data to get the most up to date tapes price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: HIBID >= LOASK\n",
      "WARNING: HIBID >= LOASK\n",
      "WARNING: HIBID >= LOASK\n",
      "WARNING: HIBID >= LOASK\n",
      "124\r"
     ]
    }
   ],
   "source": [
    "# code\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "def get_tapes_window(tapes):\n",
    "    dt = 60*60 # in seconds\n",
    "    #stds = []\n",
    "    #means = []\n",
    "    w_bids = []\n",
    "    w_asks = []\n",
    "\n",
    "    t_start = 0\n",
    "    start_time = 0\n",
    "    z = 3.29 # 99.9%\n",
    "\n",
    "    outside = []\n",
    "    while True:\n",
    "        end_time = start_time + dt\n",
    "        t_end = t_start\n",
    "        rolling_tapes = []\n",
    "        while tapes[t_end, 0] < end_time:\n",
    "            rolling_tapes += [tapes[t_end, 1]] * int(tapes[t_end,2])\n",
    "            t_end += 1\n",
    "\n",
    "        mean = np.mean(rolling_tapes)\n",
    "        std = np.std(rolling_tapes)\n",
    "        #means.append(mean)\n",
    "\n",
    "        w_bid = mean - std * z\n",
    "        w_ask = mean + std * z\n",
    "        w_bids.append(w_bid)\n",
    "        w_asks.append(w_ask)\n",
    "\n",
    "        # look one minute a head\n",
    "        local_end = t_end\n",
    "        future_tapes = []\n",
    "        while tapes[local_end, 0] < end_time + 60:\n",
    "            future_tapes += [tapes[local_end, 1]] * int(tapes[local_end,2])\n",
    "            local_end += 1\n",
    "\n",
    "        future_tapes = np.array(future_tapes)\n",
    "\n",
    "        n_above = len(np.where(future_tapes > w_ask)[0])\n",
    "        n_below = len(np.where(future_tapes < w_bid)[0])\n",
    "        if end_time % 60 !=0:\n",
    "            raise ValueError\n",
    "        outside.append((end_time,n_above, n_below, len(future_tapes)))\n",
    "\n",
    "        start_time += 60\n",
    "        while tapes[t_start, 0] < start_time:\n",
    "            t_start += 1\n",
    "\n",
    "        end_time += dt\n",
    "        if end_time >= 8.5*60*60:\n",
    "            break\n",
    "\n",
    "    return outside, w_bids, w_asks\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_features(lob_data: np.array, \n",
    "                 lob_times: np.array, \n",
    "                 tapes: np.array, \n",
    "                 time_step_s: int, \n",
    "                 window_data: np.array,\n",
    "                 ab_weight = 1, \n",
    "                 median = False, \n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Calculate features from LOB and Tapes data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lob_data : np.array\n",
    "        Array containing the limit order book (LOB) data.\n",
    "    lob_times : np.array\n",
    "        Array containing timestamps for the LOB data.\n",
    "    tapes : np.array\n",
    "        Array containing Tapes data.\n",
    "    time_step_s : int\n",
    "        Time step in seconds for calculating features.\n",
    "    ab_weight : float, optional\n",
    "        Weight parameter for alpha and beta calculations, by default 1.\n",
    "    median : bool, optional\n",
    "        Whether to calculate features using median instead of mean, by default False.\n",
    "    window_data : np.array\n",
    "        Array containing window data for calculating CBS and CAS, by default None.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        A tuple containing:\n",
    "        - feat_arr: np.array\n",
    "            Array containing feature values.\n",
    "        - features: list\n",
    "            List of feature names.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_rows = int((8.5 * 60 * 60) / time_step_s)                         # define number of rows of output array\n",
    "    features = [\"MP\",\"HIBID\",\"LOASK\",\"AP\",\"WBP\",\"WAP\",                  # define features\n",
    "                \"TCBS\",\"TCAS\",\"AWS\",\"VOL\",\"GAP\",\"SPREAD\",\n",
    "                \"ALPHA\", \"BETA\", \"ZETA\", \"ENDT\", \n",
    "                \"PSTD\", \"LOWIN\", \"HIWIN\", \"nUoD\"]\n",
    "    n_features = len(features)                                          # define number of features\n",
    "\n",
    "    feat_arr = np.zeros((n_rows, n_features), dtype=np.float64)         # array to hold feature values\n",
    "    \n",
    "    LA_HB_a_b = np.zeros((lob_data.shape[0]+1, 4), dtype = np.float64)  # array holding the LOASK, HIBID,\n",
    "                                                                        # alpha, beta, values \n",
    "\n",
    "    for i in prange(lob_data.shape[0]):                                 # iterates over the LOB to fill\n",
    "        row = lob_data[i]                                               # LA_HB_a_b values\n",
    "        \n",
    "        neg_ind = np.where(row < 0)[0]                                  # locate bid and ask prices (indicies)\n",
    "        pos_ind = np.where(row > 0)[0]\n",
    "        \n",
    "        if len(neg_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][1] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][1] = max(neg_ind) + 1 \n",
    "\n",
    "        if len(pos_ind) == 0:                                           # assign HIBID, np.nan if no values\n",
    "            LA_HB_a_b[i][0] = np.nan\n",
    "        else:\n",
    "            LA_HB_a_b[i][0] = min(pos_ind) + 1\n",
    "\n",
    "        mid_price = (LA_HB_a_b[i][0] + LA_HB_a_b[i][1]) / 2             # calculate mid_price for alpha/beta calculations\n",
    "\n",
    "        if np.isnan(mid_price):\n",
    "            alpha = np.nan\n",
    "            beta = np.nan\n",
    "        else:                                                           # calculate alpha/beta using ab_weight var\n",
    "            beta = 0\n",
    "            for ind in neg_ind:\n",
    "                beta += (-1 * row[ind]) / ((mid_price - (ind + 1)) + ab_weight)\n",
    "    \n",
    "            alpha = 0\n",
    "            for ind in pos_ind:\n",
    "                alpha += row[ind] / (((ind + 1) - mid_price) + ab_weight)\n",
    "                \n",
    "\n",
    "        LA_HB_a_b[i][2] = alpha\n",
    "        LA_HB_a_b[i][3] = beta\n",
    "        \n",
    "    max_lob = lob_data.shape[0] - 1                                      # define max indicies for lob\n",
    "    max_tapes = tapes.shape[0] - 1                                       # define max indicies for tapes\n",
    "    \n",
    "    start_time = 0                                                       # define start time\n",
    "    lob_start = 0                                                        # define start index for lob\n",
    "    tapes_start = 0                                                      # define start index for tapes\n",
    "    \n",
    "    cas = np.zeros(800, dtype = np.int16)                                # define an array to hold CAS values\n",
    "    cbs = np.zeros(800, dtype = np.int16)                                # define an array to hold CBS values\n",
    "    for row_i in range(n_rows):\n",
    "        end_time = start_time + time_step_s                              # move to next time step\n",
    "        lob_end = lob_start\n",
    "        tapes_end = tapes_start\n",
    "\n",
    "        # get lob end index\n",
    "        while lob_times[lob_end] < end_time and lob_end < max_lob:       # move lob indicies to end time\n",
    "            lob_end += 1\n",
    "        \n",
    "        # get tapes end index\n",
    "        while tapes[tapes_end][0] < end_time and tapes_end < max_tapes:  # move tapes indicies to end time\n",
    "            tapes_end += 1\n",
    "\n",
    "        # feature calculations\n",
    "        if tapes_start == tapes_end:                                     # if there is no tapes data\n",
    "            AP = np.nan                                                  # set tapes features to np.nan\n",
    "            VOL = np.nan\n",
    "            PSTD = np.nan\n",
    "            nUoD = np.nan\n",
    "        else:\n",
    "            tapes_slice = tapes[tapes_start:tapes_end]                   # extract tapes slice, calculate AP, VOL\n",
    "            tapes_list = []\n",
    "            \n",
    "            for row in tapes_slice:\n",
    "                for _ in range(int(row[2])):\n",
    "                    tapes_list.append(row[1])\n",
    "\n",
    "            tapes_list = np.array(tapes_list, dtype=np.int32)\n",
    "            AP = np.mean(tapes_list)\n",
    "            VOL = np.sum(tapes_slice[:,2])\n",
    "            PSTD = np.std(tapes_list)\n",
    "\n",
    "            tapes_price_diff = tapes_slice[:,1][1:] - tapes_slice[:,1][:-1]\n",
    "            n_ups = np.sum(tapes_price_diff > 0)\n",
    "            n_downs = np.sum(tapes_price_diff < 0)\n",
    "            nUoD = (n_ups + 1) / (n_downs + 1) - 1\n",
    "\n",
    "        if lob_start == lob_end:                                         # if there is no LOB data\n",
    "            MP = np.nan                                                  # set lob features to np.nan\n",
    "            HIBID = np.nan\n",
    "            LOASK = np.nan\n",
    "            SPREAD = np.nan\n",
    "            TCBS = np.nan\n",
    "            TCAS = np.nan\n",
    "            WBP = np.nan\n",
    "            WAP = np.nan\n",
    "            AWS = np.nan\n",
    "            ALPHA = np.nan\n",
    "            BETA = np.nan\n",
    "            ZETA = np.nan  \n",
    "        else:\n",
    "            lob_slice = lob_data[lob_start:lob_end]                       # extract slices of data \n",
    "            LA_HB_a_b_slice = LA_HB_a_b[lob_start:lob_end]                \n",
    "\n",
    "            # midprice_calcs, alpha, beta\n",
    "            if median:                                                    # calculate price features\n",
    "                HIBID = np.median(LA_HB_a_b_slice[:,1])                   # using median if set to true\n",
    "                LOASK = np.median(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.median(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.median(LA_HB_a_b_slice[:,3])\n",
    "            else:\n",
    "                HIBID = np.nanmean(LA_HB_a_b_slice[:,1])\n",
    "                LOASK = np.nanmean(LA_HB_a_b_slice[:,0])\n",
    "                ALPHA = np.nanmean(LA_HB_a_b_slice[:,2])\n",
    "                BETA = np.nanmean(LA_HB_a_b_slice[:,3])\n",
    "\n",
    "            MP = (HIBID + LOASK) / 2\n",
    "            SPREAD = LOASK - HIBID\n",
    "            ZETA = BETA - ALPHA\n",
    "\n",
    "            if HIBID >= LOASK:\n",
    "                print(\"WARNING: HIBID >= LOASK\")\n",
    "\n",
    "            # consolidated calcs\n",
    "            cas[:] = 0                                                      # reset cas, cbs arrays for new data\n",
    "            cbs[:] = 0 \n",
    "\n",
    "            window_index = np.where(window_data[:,0] == end_time)[0]\n",
    "            if len(window_index) == 1:\n",
    "                w_bid = window_data[window_index[0], 4]\n",
    "                w_ask = window_data[window_index[0], 5]\n",
    "                LOWIN = window_data[window_index[0], 1]\n",
    "                HIWIN = window_data[window_index[0], 2]\n",
    "            else:\n",
    "                w_bid = MP - 100\n",
    "                w_ask = MP + 100\n",
    "                LOWIN = 0\n",
    "                HIWIN = 0\n",
    "\n",
    "            for ci in prange(int(np.floor(w_bid) - 1), int(np.ceil(w_ask) + 2)):\n",
    "                # can optimise with LOASK AND HIBID here\n",
    "                                                                        # only calculate cbs between window left of MP\n",
    "                cbs_vec = lob_slice[:,ci].copy() * -1                   # and less than LOASK + 100 for efficiency\n",
    "                cbs_vec[cbs_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cbs[ci] = np.sum(np.abs(np.diff(cbs_vec))) + cbs_vec[0]\n",
    "\n",
    "                                                                        # only calculate cas between window right of MP\n",
    "                cas_vec = lob_slice[:,ci].copy()                        # and greater than HIBID - 100 for efficiency\n",
    "                cas_vec[cas_vec <= 0] = 0                               # idk if this breaks things for efficiency ?:\n",
    "                cas[ci] = np.sum(np.abs(np.diff(cas_vec))) + cas_vec[0]\n",
    "\n",
    "            TCBS = np.sum(cbs)                                              # Total CBS\n",
    "            TCAS = np.sum(cas)                                              # Total CAS\n",
    "\n",
    "            if TCBS == 0:                                                   # Calculate WBP, np.nan if no activity\n",
    "                WBP = np.nan\n",
    "            else:\n",
    "                WBP = 0\n",
    "                for ci in prange(800):\n",
    "                    WBP += (ci + 1) * (cbs[ci] / TCBS)\n",
    "\n",
    "            if TCAS == 0:                                                   # Calculate WAP, np.nan if no activity\n",
    "                WAP = np.nan\n",
    "            else:\n",
    "                WAP = 0\n",
    "                for ci in prange(800):\n",
    "                    WAP += (ci + 1) * (cas[ci] / TCAS)\n",
    "\n",
    "            AWS = WAP - WBP                                                 # Activity weighted spread calc\n",
    "\n",
    "        # feature setting\n",
    "        feat_arr[row_i][features.index(\"AP\")] = AP                          # set the values to the feat_arr\n",
    "        feat_arr[row_i][features.index(\"VOL\")] = VOL\n",
    "        feat_arr[row_i][features.index(\"MP\")] = MP\n",
    "        feat_arr[row_i][features.index(\"HIBID\")] = HIBID\n",
    "        feat_arr[row_i][features.index(\"LOASK\")] = LOASK\n",
    "        feat_arr[row_i][features.index(\"SPREAD\")] = SPREAD\n",
    "        feat_arr[row_i][features.index(\"TCAS\")] = TCAS\n",
    "        feat_arr[row_i][features.index(\"TCBS\")] = TCBS\n",
    "        feat_arr[row_i][features.index(\"WAP\")] = WAP\n",
    "        feat_arr[row_i][features.index(\"WBP\")] = WBP\n",
    "        feat_arr[row_i][features.index(\"AWS\")] = AWS\n",
    "        feat_arr[row_i][features.index(\"ALPHA\")] = ALPHA\n",
    "        feat_arr[row_i][features.index(\"BETA\")] = BETA\n",
    "        feat_arr[row_i][features.index(\"ZETA\")] = ZETA\n",
    "        feat_arr[row_i][features.index(\"GAP\")] = MP - AP\n",
    "        feat_arr[row_i][features.index(\"ENDT\")] = end_time\n",
    "        feat_arr[row_i][features.index(\"PSTD\")] = PSTD\n",
    "        feat_arr[row_i][features.index(\"LOWIN\")] = LOWIN\n",
    "        feat_arr[row_i][features.index(\"HIWIN\")] = HIWIN\n",
    "        feat_arr[row_i][features.index(\"nUoD\")] = nUoD\n",
    "\n",
    "\n",
    "        # adjust start times\n",
    "        start_time = end_time                                                # Set the next start times and \n",
    "        lob_start = lob_end                                                  # indicies to the last end times / indicies\n",
    "        tapes_start = tapes_end\n",
    "\n",
    "    return feat_arr, features\n",
    "\n",
    "window_length_s = 5\n",
    "c = 0\n",
    "all_features = []\n",
    "for lob, lob_times, tapes in get_data_gen():\n",
    "    print(c, end = \"\\r\")\n",
    "    outside, w_bids, w_asks = get_tapes_window(tapes)\n",
    "    window_data = np.zeros((len(outside), 6), dtype = float)\n",
    "    for i in range(len(outside)):\n",
    "        window_data[i][:4] = outside[i]\n",
    "        window_data[i][4] = w_bids[i]\n",
    "        window_data[i][5] = w_asks[i]\n",
    "\n",
    "    features = get_features(lob, lob_times, tapes, window_length_s, window_data)\n",
    "    all_features.append(features)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>HIBID</th>\n",
       "      <th>LOASK</th>\n",
       "      <th>AP</th>\n",
       "      <th>WBP</th>\n",
       "      <th>WAP</th>\n",
       "      <th>TCBS</th>\n",
       "      <th>TCAS</th>\n",
       "      <th>AWS</th>\n",
       "      <th>VOL</th>\n",
       "      <th>...</th>\n",
       "      <th>ZETA</th>\n",
       "      <th>ENDT</th>\n",
       "      <th>PSTD</th>\n",
       "      <th>LOWIN</th>\n",
       "      <th>HIWIN</th>\n",
       "      <th>nUoD</th>\n",
       "      <th>WMP</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "      <th>MP_perc(y)</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6119.000000</td>\n",
       "      <td>6119.000000</td>\n",
       "      <td>6120.000000</td>\n",
       "      <td>5858.000000</td>\n",
       "      <td>5882.000000</td>\n",
       "      <td>5981.000000</td>\n",
       "      <td>6120.000000</td>\n",
       "      <td>6120.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>5858.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6119.000000</td>\n",
       "      <td>6120.000000</td>\n",
       "      <td>5858.000000</td>\n",
       "      <td>6120.0</td>\n",
       "      <td>6120.000000</td>\n",
       "      <td>5858.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>6118.000000</td>\n",
       "      <td>6118.000000</td>\n",
       "      <td>6120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>137.610372</td>\n",
       "      <td>106.622519</td>\n",
       "      <td>168.586853</td>\n",
       "      <td>108.015732</td>\n",
       "      <td>83.529185</td>\n",
       "      <td>153.612509</td>\n",
       "      <td>139.794281</td>\n",
       "      <td>68.480719</td>\n",
       "      <td>67.181767</td>\n",
       "      <td>9.462786</td>\n",
       "      <td>...</td>\n",
       "      <td>1.715460</td>\n",
       "      <td>15302.500000</td>\n",
       "      <td>1.168765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131373</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>116.603008</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>-0.033096</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.185344</td>\n",
       "      <td>7.757566</td>\n",
       "      <td>64.878119</td>\n",
       "      <td>3.036246</td>\n",
       "      <td>14.291227</td>\n",
       "      <td>37.520198</td>\n",
       "      <td>79.645304</td>\n",
       "      <td>41.110420</td>\n",
       "      <td>29.681157</td>\n",
       "      <td>5.423445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.889333</td>\n",
       "      <td>8834.180777</td>\n",
       "      <td>1.036306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334813</td>\n",
       "      <td>0.656511</td>\n",
       "      <td>20.302044</td>\n",
       "      <td>40.268319</td>\n",
       "      <td>0.258864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>49.702381</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>93.048780</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>96.262295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.015152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.893889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.888889</td>\n",
       "      <td>63.550000</td>\n",
       "      <td>-190.273417</td>\n",
       "      <td>-1.307611</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>114.778424</td>\n",
       "      <td>106.893569</td>\n",
       "      <td>121.230369</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>73.808762</td>\n",
       "      <td>126.875000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>49.862199</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462670</td>\n",
       "      <td>7653.750000</td>\n",
       "      <td>0.441601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>102.400968</td>\n",
       "      <td>-18.215096</td>\n",
       "      <td>-0.151221</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126.898148</td>\n",
       "      <td>108.434783</td>\n",
       "      <td>145.757979</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>82.892938</td>\n",
       "      <td>143.270588</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>63.833507</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090147</td>\n",
       "      <td>15302.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>111.660144</td>\n",
       "      <td>-5.452147</td>\n",
       "      <td>-0.046152</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>151.572170</td>\n",
       "      <td>109.756837</td>\n",
       "      <td>195.794596</td>\n",
       "      <td>109.900000</td>\n",
       "      <td>93.831280</td>\n",
       "      <td>171.048387</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>82.286642</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.422440</td>\n",
       "      <td>22951.250000</td>\n",
       "      <td>1.685083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.414002</td>\n",
       "      <td>16.717696</td>\n",
       "      <td>0.121167</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>336.457627</td>\n",
       "      <td>113.389831</td>\n",
       "      <td>566.864407</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>422.594595</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>368.088345</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.880735</td>\n",
       "      <td>30600.000000</td>\n",
       "      <td>8.710211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>238.550422</td>\n",
       "      <td>220.039591</td>\n",
       "      <td>0.663839</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                MP        HIBID        LOASK           AP          WBP  \\\n",
       "count  6119.000000  6119.000000  6120.000000  5858.000000  5882.000000   \n",
       "mean    137.610372   106.622519   168.586853   108.015732    83.529185   \n",
       "std      33.185344     7.757566    64.878119     3.036246    14.291227   \n",
       "min      49.702381     2.928571    93.048780    93.000000     4.071429   \n",
       "25%     114.778424   106.893569   121.230369   107.000000    73.808762   \n",
       "50%     126.898148   108.434783   145.757979   108.500000    82.892938   \n",
       "75%     151.572170   109.756837   195.794596   109.900000    93.831280   \n",
       "max     336.457627   113.389831   566.864407   114.000000   113.000000   \n",
       "\n",
       "               WAP         TCBS         TCAS          AWS          VOL  ...  \\\n",
       "count  5981.000000  6120.000000  6120.000000  5750.000000  5858.000000  ...   \n",
       "mean    153.612509   139.794281    68.480719    67.181767     9.462786  ...   \n",
       "std      37.520198    79.645304    41.110420    29.681157     5.423445  ...   \n",
       "min      96.262295     0.000000     0.000000    -6.015152     1.000000  ...   \n",
       "25%     126.875000    85.000000    39.000000    49.862199     5.000000  ...   \n",
       "50%     143.270588   131.000000    61.000000    63.833507     9.000000  ...   \n",
       "75%     171.048387   185.000000    93.000000    82.286642    13.000000  ...   \n",
       "max     422.594595   614.000000   264.000000   368.088345    34.000000  ...   \n",
       "\n",
       "              ZETA          ENDT         PSTD   LOWIN        HIWIN  \\\n",
       "count  6119.000000   6120.000000  5858.000000  6120.0  6120.000000   \n",
       "mean      1.715460  15302.500000     1.168765     0.0     0.131373   \n",
       "std       1.889333   8834.180777     1.036306     0.0     1.334813   \n",
       "min      -2.893889      5.000000     0.000000     0.0     0.000000   \n",
       "25%       0.462670   7653.750000     0.441601     0.0     0.000000   \n",
       "50%       1.090147  15302.500000     1.000000     0.0     0.000000   \n",
       "75%       2.422440  22951.250000     1.685083     0.0     0.000000   \n",
       "max      15.880735  30600.000000     8.710211     0.0    38.000000   \n",
       "\n",
       "              nUoD          WMP   MP_diff(y)   MP_perc(y)     DAY  \n",
       "count  5858.000000  5750.000000  6118.000000  6118.000000  6120.0  \n",
       "mean     -0.122745   116.603008     0.014577    -0.033096   124.0  \n",
       "std       0.656511    20.302044    40.268319     0.258864     0.0  \n",
       "min      -0.888889    63.550000  -190.273417    -1.307611   124.0  \n",
       "25%      -0.500000   102.400968   -18.215096    -0.151221   124.0  \n",
       "50%      -0.333333   111.660144    -5.452147    -0.046152   124.0  \n",
       "75%       0.000000   127.414002    16.717696     0.121167   124.0  \n",
       "max       6.000000   238.550422   220.039591     0.663839   124.0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [pd.DataFrame(fa, columns=f) for fa, f in all_features]\n",
    "for i, df in enumerate(dfs):\n",
    "    df[\"WMP\"] = (df[\"WBP\"] + df[\"WAP\"]) / 2\n",
    "    df[\"MP_diff(y)\"] = df[\"MP\"].diff(1)\n",
    "    \n",
    "    df[\"MP_perc(y)\"] = df[\"MP_diff(y)\"] / df[\"MP\"]\n",
    "    df[\"DAY\"] = i\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from LOB and Tapes\n",
    "\n",
    "get mean, std, trend, delta from 60 min segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCAS_std</th>\n",
       "      <th>TCAS_mean</th>\n",
       "      <th>TCAS_close</th>\n",
       "      <th>TCAS_delta</th>\n",
       "      <th>TCAS_corr</th>\n",
       "      <th>TCBS_std</th>\n",
       "      <th>TCBS_mean</th>\n",
       "      <th>TCBS_close</th>\n",
       "      <th>TCBS_delta</th>\n",
       "      <th>TCBS_corr</th>\n",
       "      <th>...</th>\n",
       "      <th>PSTD_mean</th>\n",
       "      <th>PSTD_close</th>\n",
       "      <th>PSTD_delta</th>\n",
       "      <th>PSTD_corr</th>\n",
       "      <th>LOWIN_sum</th>\n",
       "      <th>HIWIN_sum</th>\n",
       "      <th>MP_diff(y)</th>\n",
       "      <th>MP_perc(y)</th>\n",
       "      <th>DAY</th>\n",
       "      <th>ENDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>39.435809</td>\n",
       "      <td>91.316667</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.087793</td>\n",
       "      <td>76.603713</td>\n",
       "      <td>154.933333</td>\n",
       "      <td>236.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.744949</td>\n",
       "      <td>-0.014051</td>\n",
       "      <td>0</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>41.205326</td>\n",
       "      <td>93.233333</td>\n",
       "      <td>187.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.031857</td>\n",
       "      <td>75.004065</td>\n",
       "      <td>157.583333</td>\n",
       "      <td>190.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-0.031917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252418</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.321256</td>\n",
       "      <td>-0.012618</td>\n",
       "      <td>0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>40.433605</td>\n",
       "      <td>91.583333</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>74.598814</td>\n",
       "      <td>157.983333</td>\n",
       "      <td>94.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-0.090751</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305758</td>\n",
       "      <td>4.346135</td>\n",
       "      <td>3.023259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.460145</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>40.572226</td>\n",
       "      <td>89.833333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>74.141102</td>\n",
       "      <td>160.383333</td>\n",
       "      <td>217.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.102357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303052</td>\n",
       "      <td>1.165922</td>\n",
       "      <td>-0.554543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.569652</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>41.262089</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-0.047814</td>\n",
       "      <td>75.727910</td>\n",
       "      <td>162.016667</td>\n",
       "      <td>283.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-0.044702</td>\n",
       "      <td>...</td>\n",
       "      <td>1.325510</td>\n",
       "      <td>3.023060</td>\n",
       "      <td>1.302979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.910348</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>0</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>36.446990</td>\n",
       "      <td>82.183333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>59.920807</td>\n",
       "      <td>136.283333</td>\n",
       "      <td>226.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.053973</td>\n",
       "      <td>...</td>\n",
       "      <td>1.614588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.279304</td>\n",
       "      <td>-0.011390</td>\n",
       "      <td>0</td>\n",
       "      <td>30580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>36.415484</td>\n",
       "      <td>82.250000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.019438</td>\n",
       "      <td>67.132200</td>\n",
       "      <td>139.966667</td>\n",
       "      <td>373.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.058805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631128</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>-1.334799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.034188</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>0</td>\n",
       "      <td>30585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>36.714877</td>\n",
       "      <td>81.866667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-0.064194</td>\n",
       "      <td>67.890375</td>\n",
       "      <td>141.283333</td>\n",
       "      <td>219.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.091213</td>\n",
       "      <td>...</td>\n",
       "      <td>1.697071</td>\n",
       "      <td>6.036348</td>\n",
       "      <td>4.155999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.287167</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0</td>\n",
       "      <td>30590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>36.322395</td>\n",
       "      <td>81.183333</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-0.031543</td>\n",
       "      <td>70.107148</td>\n",
       "      <td>143.433333</td>\n",
       "      <td>278.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700208</td>\n",
       "      <td>2.059126</td>\n",
       "      <td>2.059126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.249827</td>\n",
       "      <td>-0.025534</td>\n",
       "      <td>0</td>\n",
       "      <td>30595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>36.448274</td>\n",
       "      <td>81.300000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>69.850117</td>\n",
       "      <td>142.166667</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>0.159203</td>\n",
       "      <td>...</td>\n",
       "      <td>1.765851</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>2.651933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.164680</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0</td>\n",
       "      <td>30600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6060 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TCAS_std  TCAS_mean  TCAS_close  TCAS_delta  TCAS_corr   TCBS_std  \\\n",
       "60    39.435809  91.316667        80.0         8.0  -0.087793  76.603713   \n",
       "61    41.205326  93.233333       187.0        26.0  -0.031857  75.004065   \n",
       "62    40.433605  91.583333        62.0       -78.0  -0.005201  74.598814   \n",
       "63    40.572226  89.833333        35.0       -58.0  -0.009749  74.141102   \n",
       "64    41.262089  88.800000        31.0       -89.0  -0.047814  75.727910   \n",
       "...         ...        ...         ...         ...        ...        ...   \n",
       "6115  36.446990  82.183333        26.0       -37.0   0.007855  59.920807   \n",
       "6116  36.415484  82.250000        67.0         2.0  -0.019438  67.132200   \n",
       "6117  36.714877  81.866667        42.0       -81.0  -0.064194  67.890375   \n",
       "6118  36.322395  81.183333        82.0       -35.0  -0.031543  70.107148   \n",
       "6119  36.448274  81.300000       124.0        72.0   0.030761  69.850117   \n",
       "\n",
       "       TCBS_mean  TCBS_close  TCBS_delta  TCBS_corr  ...  PSTD_mean  \\\n",
       "60    154.933333       236.0       205.0   0.003241  ...   1.246211   \n",
       "61    157.583333       190.0       120.0  -0.031917  ...   1.252418   \n",
       "62    157.983333        94.0        21.0  -0.090751  ...   1.305758   \n",
       "63    160.383333       217.0        32.0  -0.102357  ...   1.303052   \n",
       "64    162.016667       283.0      -192.0  -0.044702  ...   1.325510   \n",
       "...          ...         ...         ...        ...  ...        ...   \n",
       "6115  136.283333       226.0        74.0  -0.053973  ...   1.614588   \n",
       "6116  139.966667       373.0       233.0   0.058805  ...   1.631128   \n",
       "6117  141.283333       219.0        70.0   0.091213  ...   1.697071   \n",
       "6118  143.433333       278.0        83.0   0.146924  ...   1.700208   \n",
       "6119  142.166667       119.0       -55.0   0.159203  ...   1.765851   \n",
       "\n",
       "      PSTD_close  PSTD_delta  PSTD_corr  LOWIN_sum  HIWIN_sum  MP_diff(y)  \\\n",
       "60      0.000000         NaN        NaN        0.0        0.0   -3.744949   \n",
       "61      1.600000         NaN        NaN        0.0        0.0   -3.321256   \n",
       "62      4.346135    3.023259        NaN        0.0        0.0    1.460145   \n",
       "63      1.165922   -0.554543        NaN        0.0        0.0   -0.569652   \n",
       "64      3.023060    1.302979        NaN        0.0        0.0   -1.910348   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "6115    0.000000    0.000000        NaN        0.0        0.0   -3.279304   \n",
       "6116    0.942809   -1.334799        NaN        0.0        0.0   -2.034188   \n",
       "6117    6.036348    4.155999        NaN        0.0        0.0    5.287167   \n",
       "6118    2.059126    2.059126        NaN        0.0        0.0   -7.249827   \n",
       "6119    3.741657    2.651933        NaN        0.0        0.0    3.164680   \n",
       "\n",
       "      MP_perc(y)  DAY     ENDT  \n",
       "60     -0.014051    0    305.0  \n",
       "61     -0.012618    0    310.0  \n",
       "62      0.005517    0    315.0  \n",
       "63     -0.002157    0    320.0  \n",
       "64     -0.007286    0    325.0  \n",
       "...          ...  ...      ...  \n",
       "6115   -0.011390    0  30580.0  \n",
       "6116   -0.007115    0  30585.0  \n",
       "6117    0.018158    0  30590.0  \n",
       "6118   -0.025534    0  30595.0  \n",
       "6119    0.011023    0  30600.0  \n",
       "\n",
       "[6060 rows x 59 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "features = [\"TCAS\", \"TCBS\", \"ALPHA\", \"BETA\", \"ZETA\",\n",
    "            \"WMP\", \"AWS\", \"VOL\", \"GAP\", \"nUoD\", \"PSTD\"]\n",
    "\n",
    "sum_features = [\"LOWIN\", \"HIWIN\"]\n",
    "\n",
    "y_feats = [\"MP_diff(y)\", \"MP_perc(y)\", \"DAY\"]\n",
    "\n",
    "X_dfs = []\n",
    "\n",
    "\n",
    "\n",
    "for c, df in enumerate(dfs):\n",
    "    print(c, end = \"\\r\")\n",
    "\n",
    "    X_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df) - 60):\n",
    "        train_segment = df[i:i+60]\n",
    "        test_segment = df[i+60:i+61]\n",
    "\n",
    "        row = {}\n",
    "        for f in features:\n",
    "            # std\n",
    "            row[f+\"_std\"] = np.std(train_segment[f])\n",
    "            # mean\n",
    "            if f != \"WMP\": # exclude mean midprice\n",
    "                row[f+\"_mean\"] = np.mean(train_segment[f])\n",
    "                row[f+\"_close\"] = train_segment[f].iloc[-1]\n",
    "            # delta\n",
    "            row[f+\"_delta\"] = train_segment[f].iloc[-1] - train_segment[f].iloc[0]\n",
    "            # trend\n",
    "            row[f+\"_corr\"] = np.corrcoef(np.arange(len(train_segment[f])), train_segment[f].to_numpy())[0, 1]\n",
    "\n",
    "        for f in sum_features:\n",
    "            row[f+\"_sum\"] = np.sum(train_segment[f])\n",
    "\n",
    "        for yf in y_feats:\n",
    "            row[yf] = test_segment[yf].iloc[0]\n",
    "        row[\"ENDT\"] = test_segment[\"ENDT\"]\n",
    "\n",
    "        X_df = pd.concat([X_df, pd.DataFrame(row)])\n",
    "\n",
    "    X_dfs.append(X_df)\n",
    "\n",
    "X_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = pd.concat(X_dfs[:], axis = 0)\n",
    "merged_dfs.to_csv(f\"final_merged_{window_length_s}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clean_merge_dfs = merged_dfs.dropna(how=\"any\")\n",
    "\n",
    "x_features = list(X_df)\n",
    "x_features.remove(y_feat)\n",
    "\n",
    "X = clean_merge_dfs[x_features]\n",
    "y = 1 / (1 + np.exp(-clean_merge_dfs[y_feat]/4))\n",
    "\n",
    "baseline_mae = np.mean(np.abs(y - 0.5))\n",
    "print(\"Baseline MAE: \", baseline_mae)\n",
    "print(\"Samples: \", len(merged_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X contains your input features and y contains your target values\n",
    "# X shape: (number of samples, 35)\n",
    "\n",
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "# Step 2: Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DTR = DecisionTreeRegressor(max_leaf_nodes=10)\n",
    "DTR.fit(X_train, y_train)\n",
    "\n",
    "ypred = DTR.predict(X_test)\n",
    "print(mean_absolute_error(ypred, y_test))\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plot_tree(DTR, feature_names=x_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(ypred)\n",
    "plt.plot(y_test.to_numpy())\n",
    "plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(x_features, DTR.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svc = SVR()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "ypred = SVR.predict(X_test)\n",
    "print(mean_absolute_error(ypred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "\n",
    "def create_regression_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "        layers.Dropout(0.2),  # Add Dropout layer\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid')  # Output layer with single neuron for regression\n",
    "    ])\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=0.05)\n",
    "    model.compile(optimizer=opt, loss='mean_absolute_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (len(x_features),)\n",
    "regression_model = create_regression_model(input_shape)\n",
    "\n",
    "# Display model architecture\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "history = regression_model.fit(X_train_normalized, y_train, epochs=1000, batch_size=512, validation_split=0.5, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.axhline(baseline_mae, c = \"black\", linestyle = \"--\")\n",
    "plt.show()\n",
    "\n",
    "test_loss = regression_model.evaluate(X_test_normalized, y_test)\n",
    "model_filename = f\"regression_model_test_score_{test_loss[-1]:.4f}.keras\"\n",
    "regression_model.save(model_filename)\n",
    "# Print the test loss\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features\n",
    "\n",
    "for use in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs.to_csv(\"final_merged_5s.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged_dfs = pd.read_csv(\"final_merged_15s.csv\", index_col=0)\n",
    "plt.figure(figsize=(50,40))\n",
    "sns.heatmap(merged_dfs.corr(), vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "merged_dfs = pd.read_csv(\"final_merged_15s.csv\", index_col=0)\n",
    "x_features = list(merged_dfs)\n",
    "x_features.remove(\"MP_diff(y)\")\n",
    "x_features.remove(\"LOWIN_sum\")\n",
    "\n",
    "clean_dfs = merged_dfs.dropna(how=\"any\")\n",
    "\n",
    "for col in x_features:\n",
    "    std = clean_dfs[col].std()\n",
    "    mean = clean_dfs[col].mean()\n",
    "\n",
    "    clean_dfs[col] = (clean_dfs[col] - mean) / std\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_results = pca.fit_transform(clean_dfs[x_features])\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(pca_results[:,0], pca_results[:,1], c = np.log(clean_dfs[\"MP_diff(y)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
